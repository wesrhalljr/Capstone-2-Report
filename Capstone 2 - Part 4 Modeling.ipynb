{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "767b32b9-36c4-4ed1-b251-ad99b32e11c7",
   "metadata": {},
   "source": [
    "Capstone 2 - Part 4 Modeling by Wesley Hall\n",
    "In this section, we train and test models, then fit our data using various machine learning methods, including Random Forest Classifier,\n",
    "KMeans Clustering, and Linear Regression. We look at how well the models work and use the best to make predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14de4a76-a830-42b1-846e-d987988d375e",
   "metadata": {},
   "source": [
    "We call our training and test data, but remembering that our 'ZipCode' column should be treated as a categorical feature rather than a numeric one. Let's handle this by excluding 'ZipCode' from the K-Means clustering and ensuring all other columns are numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "081d5354-5d00-4c55-b644-a519b34db195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          BUSINESS NAME    ZIP CODE   NAICS LOCATION START DATE  \\\n",
      "0        SUSAN K TENNER  90034-6505  541600          01/01/2019   \n",
      "1  ROBERT D KAMINSKI JR  90034-3001  541600          01/01/2019   \n",
      "2          ANDREW LEVEY  90034-1816  541600          11/30/2019   \n",
      "3         JOHANNES SAAM  90034-1612  541510          01/01/2019   \n",
      "4          MELISSA SATO  90034-6108  541700          01/01/2019   \n",
      "\n",
      "   LOCATION END DATE              LOCATION  \\\n",
      "0                NaN  (34.0189, -118.4195)   \n",
      "1                NaN  (34.0252, -118.4194)   \n",
      "2                NaN  (34.0392, -118.3954)   \n",
      "3                NaN  (34.0404, -118.3733)   \n",
      "4                NaN  (34.0182, -118.4185)   \n",
      "\n",
      "                           PRIMARY NAICS DESCRIPTION  Pop 18-24 Some College  \\\n",
      "0  Management, scientific, & technical consulting...                -0.26269   \n",
      "1  Management, scientific, & technical consulting...                -0.26269   \n",
      "2  Management, scientific, & technical consulting...                -0.26269   \n",
      "3         Computer systems design & related services                -0.26269   \n",
      "4         Scientific research & development services                -0.26269   \n",
      "\n",
      "   Pop 18-24 Bachelors+  Pop 25-34 HS+  ...  Pop 45-64 Bachelors+  \\\n",
      "0              -0.09464       2.077705  ...              0.311833   \n",
      "1              -0.09464       2.077705  ...              0.311833   \n",
      "2              -0.09464       2.077705  ...              0.311833   \n",
      "3              -0.09464       2.077705  ...              0.311833   \n",
      "4              -0.09464       2.077705  ...              0.311833   \n",
      "\n",
      "   Pop 65+ HS+  Pop 65+ Bachelors+  ZipCode  Year       PC1       PC2  \\\n",
      "0     -0.38328           -0.305031    90034  2019 -1.923375 -1.965059   \n",
      "1     -0.38328           -0.305031    90034  2019 -1.923375 -1.965059   \n",
      "2     -0.38328           -0.305031    90034  2019 -1.923375 -1.965059   \n",
      "3     -0.38328           -0.305031    90034  2019 -1.923375 -1.965059   \n",
      "4     -0.38328           -0.305031    90034  2019 -1.923375 -1.965059   \n",
      "\n",
      "        PC3       PC4       PC5  \n",
      "0  1.563025 -0.238274 -0.232212  \n",
      "1  1.563025 -0.238274 -0.232212  \n",
      "2  1.563025 -0.238274 -0.232212  \n",
      "3  1.563025 -0.238274 -0.232212  \n",
      "4  1.563025 -0.238274 -0.232212  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the merged_data_with_pca dataset from the saved CSV file\n",
    "merged_data_with_pca = pd.read_csv('merged_data_with_pca.csv')\n",
    "\n",
    "# Check the first few rows to confirm the data is loaded correctly\n",
    "print(merged_data_with_pca.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d588677-85f2-4f9c-942f-70f0da444861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ZipCode\n",
      "0    90034\n",
      "1    90034\n",
      "2    90034\n",
      "3    90034\n",
      "4    90034\n"
     ]
    }
   ],
   "source": [
    "# Convert ZipCode to string before splitting\n",
    "merged_data_with_pca['ZipCode'] = merged_data_with_pca['ZipCode'].astype(str)\n",
    "\n",
    "# Remove the 4-digit extension and keep only the first 5 digits of the ZipCode\n",
    "merged_data_with_pca['ZipCode'] = merged_data_with_pca['ZipCode'].str.split('-').str[0]\n",
    "\n",
    "# Convert ZipCode back to integer (optional)\n",
    "merged_data_with_pca['ZipCode'] = merged_data_with_pca['ZipCode'].astype(int)\n",
    "\n",
    "# Verify the transformation\n",
    "print(merged_data_with_pca[['ZipCode']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f5c0725-3170-457e-97d7-c0ebb04b08d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc5f6129-95b9-4b7c-b042-1b99af8db8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (X): Index(['ZIP CODE', 'Pop 18-24 Some College', 'Pop 18-24 Bachelors+',\n",
      "       'Pop 25-34 HS+', 'Pop 25-34 Bachelors+', 'Pop 35-44 HS+',\n",
      "       'Pop 35-44 Bachelors+', 'Pop 45-64 HS+', 'Pop 45-64 Bachelors+',\n",
      "       'Pop 65+ HS+', 'Pop 65+ Bachelors+', 'ZipCode', 'PC1', 'PC2', 'PC3',\n",
      "       'PC4', 'PC5'],\n",
      "      dtype='object')\n",
      "Target (y): 0    541600\n",
      "1    541600\n",
      "2    541600\n",
      "3    541510\n",
      "4    541700\n",
      "Name: NAICS, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define the features (e.g., PCA components, ZipCode) and target (NAICS)\n",
    "X = merged_data_with_pca.drop(columns=['NAICS', 'Year', 'BUSINESS NAME', 'LOCATION START DATE', 'LOCATION END DATE', 'PRIMARY NAICS DESCRIPTION', 'LOCATION'])\n",
    "y = merged_data_with_pca['NAICS']\n",
    "\n",
    "# Verify the features and target\n",
    "print(\"Features (X):\", X.columns)\n",
    "print(\"Target (y):\", y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f85f6f9f-0b87-45b5-a200-3f665a5fa2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (2776, 16)\n",
      "Testing set size: (695, 16)\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      518210       0.12      0.02      0.04        41\n",
      "      519100       0.00      0.00      0.00        31\n",
      "      541510       0.19      0.04      0.06       134\n",
      "      541600       0.68      0.95      0.79       467\n",
      "      541612       0.00      0.00      0.00         1\n",
      "      541613       0.00      0.00      0.00         1\n",
      "      541700       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.65       695\n",
      "   macro avg       0.14      0.14      0.13       695\n",
      "weighted avg       0.50      0.65      0.55       695\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  1   1   2  37   0   0   0]\n",
      " [  2   0   0  29   0   0   0]\n",
      " [  2   0   5 127   0   0   0]\n",
      " [  2   3  17 445   0   0   0]\n",
      " [  0   0   0   1   0   0   0]\n",
      " [  0   0   1   0   0   0   0]\n",
      " [  1   0   1  18   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/admin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/admin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = merged_data_with_pca[['Pop 18-24 Some College', 'Pop 18-24 Bachelors+', \n",
    "                          'Pop 25-34 HS+', 'Pop 25-34 Bachelors+', \n",
    "                          'Pop 35-44 HS+', 'Pop 35-44 Bachelors+', \n",
    "                          'Pop 45-64 HS+', 'Pop 45-64 Bachelors+', \n",
    "                          'Pop 65+ HS+', 'Pop 65+ Bachelors+', \n",
    "                          'ZipCode', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5']]  # Features\n",
    "\n",
    "y = merged_data_with_pca['NAICS']  # Target (NAICS code)\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Testing set size:\", X_test.shape)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca84629b-9f97-4e6f-a379-86d92f1b5a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING ABOVE INDICATES CLASS IMBALANCE AND WE WILL ADDRESS HERE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4b3dc89-d5a0-4e28-9d57-d45f9b23b104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report with Class Weights:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      334220       0.00      0.00      0.00         0\n",
      "      518210       0.05      0.12      0.07        41\n",
      "      519100       0.05      0.19      0.07        31\n",
      "      541510       0.20      0.24      0.22       134\n",
      "      541519       0.00      0.00      0.00         0\n",
      "      541600       0.66      0.22      0.33       467\n",
      "      541612       0.00      0.00      0.00         1\n",
      "      541613       0.00      0.00      0.00         1\n",
      "      541700       0.01      0.10      0.03        20\n",
      "\n",
      "    accuracy                           0.21       695\n",
      "   macro avg       0.11      0.10      0.08       695\n",
      "weighted avg       0.49      0.21      0.27       695\n",
      "\n",
      "Confusion Matrix with Class Weights:\n",
      " [[  0   0   0   0   0   0   0   0   0]\n",
      " [  0   5   8   7   1   8   0   0  12]\n",
      " [  1   7   6   4   0   7   0   0   6]\n",
      " [  0  21  27  32   1  32   0   0  21]\n",
      " [  0   0   0   0   0   0   0   0   0]\n",
      " [  4  60  89 110   1 103   0   2  98]\n",
      " [  0   0   1   0   0   0   0   0   0]\n",
      " [  0   0   0   1   0   0   0   0   0]\n",
      " [  0   4   2   6   0   6   0   0   2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/admin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/admin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/admin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/admin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/admin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Re-train the Random Forest with class weights to handle imbalance\n",
    "rf_classifier_weighted = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "\n",
    "# Train the model\n",
    "rf_classifier_weighted.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_weighted = rf_classifier_weighted.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report with Class Weights:\\n\", classification_report(y_test, y_pred_weighted))\n",
    "print(\"Confusion Matrix with Class Weights:\\n\", confusion_matrix(y_test, y_pred_weighted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd2433be-c980-494a-8109-f541334b6a94",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_print_elapsed_time' from 'sklearn.utils' (/Users/admin/anaconda3/lib/python3.11/site-packages/sklearn/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/__init__.py:53\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m combine\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ensemble\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exceptions\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/ensemble/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`imblearn.ensemble` module include methods generating\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03munder-sampled subsets combined inside an ensemble.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_easy_ensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EasyEnsembleClassifier\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bagging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BalancedBaggingClassifier\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_forest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BalancedRandomForestClassifier\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/ensemble/_easy_ensemble.py:21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_docstring\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _random_state_docstring\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _deprecate_positional_args\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[1;32m     23\u001b[0m MAX_INT \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax\n\u001b[1;32m     26\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\n\u001b[1;32m     27\u001b[0m     sampling_strategy\u001b[38;5;241m=\u001b[39mBaseUnderSampler\u001b[38;5;241m.\u001b[39m_sampling_strategy_docstring,\n\u001b[1;32m     28\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m_n_jobs_docstring,\n\u001b[1;32m     29\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m_random_state_docstring,\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mEasyEnsembleClassifier\u001b[39;00m(BaggingClassifier):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/pipeline.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _print_elapsed_time\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetaestimators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m if_delegate_has_method\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_memory\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_print_elapsed_time' from 'sklearn.utils' (/Users/admin/anaconda3/lib/python3.11/site-packages/sklearn/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a4d25bd-edff-404b-b0e7-8fe2c4df641e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          BUSINESS NAME    ZIP CODE   NAICS LOCATION START DATE  \\\n",
      "0        SUSAN K TENNER  90034-6505  541600          01/01/2019   \n",
      "1  ROBERT D KAMINSKI JR  90034-3001  541600          01/01/2019   \n",
      "2          ANDREW LEVEY  90034-1816  541600          11/30/2019   \n",
      "3         JOHANNES SAAM  90034-1612  541510          01/01/2019   \n",
      "4          MELISSA SATO  90034-6108  541700          01/01/2019   \n",
      "\n",
      "   LOCATION END DATE              LOCATION  \\\n",
      "0                NaN  (34.0189, -118.4195)   \n",
      "1                NaN  (34.0252, -118.4194)   \n",
      "2                NaN  (34.0392, -118.3954)   \n",
      "3                NaN  (34.0404, -118.3733)   \n",
      "4                NaN  (34.0182, -118.4185)   \n",
      "\n",
      "                           PRIMARY NAICS DESCRIPTION  Pop 18-24 Some College  \\\n",
      "0  Management, scientific, & technical consulting...                -0.26269   \n",
      "1  Management, scientific, & technical consulting...                -0.26269   \n",
      "2  Management, scientific, & technical consulting...                -0.26269   \n",
      "3         Computer systems design & related services                -0.26269   \n",
      "4         Scientific research & development services                -0.26269   \n",
      "\n",
      "   Pop 18-24 Bachelors+  Pop 25-34 HS+  ...  Pop 45-64 Bachelors+  \\\n",
      "0              -0.09464       2.077705  ...              0.311833   \n",
      "1              -0.09464       2.077705  ...              0.311833   \n",
      "2              -0.09464       2.077705  ...              0.311833   \n",
      "3              -0.09464       2.077705  ...              0.311833   \n",
      "4              -0.09464       2.077705  ...              0.311833   \n",
      "\n",
      "   Pop 65+ HS+  Pop 65+ Bachelors+  ZipCode  Year       PC1       PC2  \\\n",
      "0     -0.38328           -0.305031    90034  2019 -1.923375 -1.965059   \n",
      "1     -0.38328           -0.305031    90034  2019 -1.923375 -1.965059   \n",
      "2     -0.38328           -0.305031    90034  2019 -1.923375 -1.965059   \n",
      "3     -0.38328           -0.305031    90034  2019 -1.923375 -1.965059   \n",
      "4     -0.38328           -0.305031    90034  2019 -1.923375 -1.965059   \n",
      "\n",
      "        PC3       PC4       PC5  \n",
      "0  1.563025 -0.238274 -0.232212  \n",
      "1  1.563025 -0.238274 -0.232212  \n",
      "2  1.563025 -0.238274 -0.232212  \n",
      "3  1.563025 -0.238274 -0.232212  \n",
      "4  1.563025 -0.238274 -0.232212  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the merged_data_with_pca dataset from the saved CSV file\n",
    "merged_data_with_pca = pd.read_csv('merged_data_with_pca.csv')\n",
    "\n",
    "# Check the first few rows to ensure it's loaded correctly\n",
    "print(merged_data_with_pca.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bb44108-c287-406c-893b-9b38283cf369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features (X) and target (y)\n",
    "X = merged_data_with_pca[['PC1', 'PC2', 'PC3', 'PC4', 'PC5']]\n",
    "y = merged_data_with_pca['NAICS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adb9b94b-c0f1-452d-ac0e-00f68a958101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0218e93-baa5-4ceb-87e3-37a0cc221bf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 1, n_samples = 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Apply SMOTE to the training data\u001b[39;00m\n\u001b[1;32m      4\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m X_train_resampled, y_train_resampled \u001b[38;5;241m=\u001b[39m smote\u001b[38;5;241m.\u001b[39mfit_resample(X_train, y_train)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/base.py:83\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     77\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[1;32m     81\u001b[0m )\n\u001b[0;32m---> 83\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resample(X, y)\n\u001b[1;32m     85\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     86\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     87\u001b[0m )\n\u001b[1;32m     89\u001b[0m X_, y_ \u001b[38;5;241m=\u001b[39m arrays_transformer\u001b[38;5;241m.\u001b[39mtransform(output[\u001b[38;5;241m0\u001b[39m], y_)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/over_sampling/_smote/base.py:324\u001b[0m, in \u001b[0;36mSMOTE._fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    321\u001b[0m X_class \u001b[38;5;241m=\u001b[39m _safe_indexing(X, target_class_indices)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_k_\u001b[38;5;241m.\u001b[39mfit(X_class)\n\u001b[0;32m--> 324\u001b[0m nns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_k_\u001b[38;5;241m.\u001b[39mkneighbors(X_class, return_distance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    325\u001b[0m X_new, y_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_samples(\n\u001b[1;32m    326\u001b[0m     X_class, y\u001b[38;5;241m.\u001b[39mdtype, class_sample, X_class, nns, n_samples, \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m    327\u001b[0m )\n\u001b[1;32m    328\u001b[0m X_resampled\u001b[38;5;241m.\u001b[39mappend(X_new)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py:834\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    833\u001b[0m         inequality_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_neighbors <= n_samples_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 834\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    835\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minequality_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    836\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_neighbors = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_neighbors\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, n_samples_fit = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_samples_fit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    837\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# include n_samples for common tests\u001b[39;00m\n\u001b[1;32m    838\u001b[0m     )\n\u001b[1;32m    840\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[1;32m    841\u001b[0m chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 1, n_samples = 1"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee4263b4-9555-4180-8b30-eb90fe7377b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({541600: 1797, 541510: 515, 518210: 189, 519100: 171, 541700: 100, 334220: 1, 541613: 1, 541519: 1, 335999: 1})\n",
      "NAICS\n",
      "541600    1797\n",
      "541510     515\n",
      "518210     189\n",
      "519100     171\n",
      "541700     100\n",
      "334220       1\n",
      "541613       1\n",
      "541519       1\n",
      "335999       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# If y_train is a numpy array or pandas series\n",
    "print(Counter(y_train))\n",
    "\n",
    "# If y_train is a pandas series\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bb0cb8c-8464-4094-9f85-92f75ab62c97",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SMOTE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m X_train_filtered \u001b[38;5;241m=\u001b[39m X_train[y_train\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;241m334220\u001b[39m, \u001b[38;5;241m541613\u001b[39m, \u001b[38;5;241m541519\u001b[39m, \u001b[38;5;241m335999\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Then apply SMOTE\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      7\u001b[0m X_train_resampled, y_train_resampled \u001b[38;5;241m=\u001b[39m smote\u001b[38;5;241m.\u001b[39mfit_resample(X_train_filtered, y_train_filtered)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SMOTE' is not defined"
     ]
    }
   ],
   "source": [
    "# Remove classes with only one sample\n",
    "y_train_filtered = y_train[y_train.isin([334220, 541613, 541519, 335999]) == False]\n",
    "X_train_filtered = X_train[y_train.isin([334220, 541613, 541519, 335999]) == False]\n",
    "\n",
    "# Then apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_filtered, y_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb53cb13-898d-45a5-bf59-aa51e6aba591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(\n",
    "    X_train_resampled, y_train_resampled, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "753310f8-b4ae-4ba7-a307-229f66cf58df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize and train the classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train_final, y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f221eb8a-4d20-45b1-a6f1-2cfbda52c78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best cross-validation score: 0.5757373400111296\n",
      "Decision Tree Accuracy: 0.8041179744017808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      518210       0.89      0.85      0.87       336\n",
      "      519100       0.92      0.88      0.90       358\n",
      "      541510       0.73      0.72      0.72       369\n",
      "      541600       0.59      0.68      0.63       361\n",
      "      541700       0.95      0.90      0.92       373\n",
      "\n",
      "    accuracy                           0.80      1797\n",
      "   macro avg       0.81      0.80      0.81      1797\n",
      "weighted avg       0.81      0.80      0.81      1797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Initialize the Decision Tree\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid for tuning\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Perform Grid Search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best parameters and score\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_}\")\n",
    "\n",
    "# Train the model with the best parameters\n",
    "best_tree = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_tree = best_tree.predict(X_test_final)\n",
    "print(f\"Decision Tree Accuracy: {accuracy_score(y_test_final, y_pred_tree)}\")\n",
    "print(classification_report(y_test_final, y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a7ed912-adf1-46a8-9bc2-e72cf7c04c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.803561491374513\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      518210       0.93      0.83      0.88       336\n",
      "      519100       0.92      0.88      0.90       358\n",
      "      541510       0.73      0.70      0.72       369\n",
      "      541600       0.58      0.69      0.63       361\n",
      "      541700       0.92      0.92      0.92       373\n",
      "\n",
      "    accuracy                           0.80      1797\n",
      "   macro avg       0.82      0.80      0.81      1797\n",
      "weighted avg       0.81      0.80      0.81      1797\n",
      "\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=4, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=4, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=4, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=4, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=4, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=4, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=4, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=4, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=4, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=4, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=4, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=1, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=1, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=2, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=4, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=3, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_leaf=4, min_samples_split=5; total time=   0.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_leaf=4, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=2, min_samples_split=2; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=3, min_samples_leaf=4, min_samples_split=10; total time=   0.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=4, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=4, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=4, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_leaf=4, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=2; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=5; total time=   0.1s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_leaf=4, min_samples_split=10; total time=   0.1s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Train the RFC on the resampled data\n",
    "rf_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = rf_clf.predict(X_test_final)\n",
    "\n",
    "# Evaluate the RFC model\n",
    "print(f\"Random Forest Accuracy: {accuracy_score(y_test_final, y_pred_rf)}\")\n",
    "print(classification_report(y_test_final, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b0ae3f-1865-4903-818c-f08b601bae83",
   "metadata": {},
   "source": [
    "The Random Forest Classifier (RFC) has produced very similar results to the tuned Decision Tree, with an accuracy of 80.36%, which is nearly identical to the Decision Tree's 80.4%. Here’s a comparison of the two models:\n",
    "\n",
    "Model Comparison:\n",
    "Metric\t               Decision Tree\tRandom Forest\n",
    "Accuracy\t               80.41%\t      80.36%\n",
    "Precision (macro avg)\t   81%\t          82%\n",
    "Recall (macro avg)\t       80%\t          80%\n",
    "F1-Score (macro avg)\t   81%\t          81%\n",
    "Observations:\n",
    "Class 518210: The Random Forest has a higher precision but slightly lower recall compared to the Decision Tree.\n",
    "Class 541600: Both models still struggle with this class, though the recall for Random Forest is slightly higher (69% vs. 68%), indicating that it handles this class slightly better.\n",
    "Overall, both models are performing almost identically in terms of overall accuracy and class-specific metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4971f70b-3156-499b-aad8-b08ecb54c99d",
   "metadata": {},
   "source": [
    "Let's TUNE our RFC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55a52628-d044-4079-9ef3-241d4cb42c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best cross-validation score: 0.6124652198107958\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(rf_clf, param_grid_rf, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search_rf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "print(f\"Best parameters: {grid_search_rf.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search_rf.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac7c5979-d7c6-40d2-ba1f-4dfbb2e12210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Feature importances\n",
    "feature_importances = rf_clf.feature_importances_\n",
    "sorted_indices = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "plt.barh(range(len(sorted_indices)), feature_importances[sorted_indices])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f2bae38-6709-4626-8e89-da665052db3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Random Forest Accuracy: 0.7824151363383417\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      518210       0.89      0.81      0.85       336\n",
      "      519100       0.88      0.84      0.86       358\n",
      "      541510       0.72      0.66      0.69       369\n",
      "      541600       0.58      0.70      0.64       361\n",
      "      541700       0.89      0.90      0.90       373\n",
      "\n",
      "    accuracy                           0.78      1797\n",
      "   macro avg       0.79      0.78      0.79      1797\n",
      "weighted avg       0.79      0.78      0.79      1797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the Random Forest with the best parameters from GridSearch\n",
    "rf_clf_tuned = RandomForestClassifier(\n",
    "    random_state=42, \n",
    "    max_depth=None, \n",
    "    min_samples_leaf=1, \n",
    "    min_samples_split=5, \n",
    "    n_estimators=200,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the tuned Random Forest model\n",
    "rf_clf_tuned.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf_tuned = rf_clf_tuned.predict(X_test_final)\n",
    "\n",
    "# Evaluate the tuned Random Forest model\n",
    "print(f\"Tuned Random Forest Accuracy: {accuracy_score(y_test_final, y_pred_rf_tuned)}\")\n",
    "print(classification_report(y_test_final, y_pred_rf_tuned))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e7fe93-a763-445a-b371-de52776b66cb",
   "metadata": {},
   "source": [
    "The tuned Random Forest Classifier achieved an accuracy of 78.2%, which is slightly lower than the untuned version (around 80%). Here’s an analysis of the performance:\n",
    "\n",
    "Key Observations:\n",
    "Accuracy: The accuracy dropped slightly compared to the untuned version, but it’s still in a reasonable range for Random Forest.\n",
    "Class 541600: The performance for class 541600 improved in recall (70%) but still shows a lower precision and F1-score compared to the other classes.\n",
    "Overall Performance: The model seems to perform well for most classes, but tuning didn’t significantly improve the overall accuracy or performance for the difficult-to-classify classes\n",
    "\n",
    "WE WILL PROCEED WITH ENSEMBLE METHOD NOW:\n",
    "Ensemble methods combine predictions from multiple machine learning algorithms to make more accurate predictions than any individual model. Here are some common ensemble techniques:\n",
    "\n",
    "Voting Classifier: Combines different models and predicts the class that gets the majority vote (hard voting) or the highest average probability (soft voting).\n",
    "Bagging (Bootstrap Aggregating): Trains multiple instances of the same algorithm on different subsets of the data.\n",
    "Boosting: Sequentially trains models, each trying to correct the errors of the previous one (e.g., AdaBoost, Gradient Boosting).\n",
    "Stacking: Combines multiple classification models via a meta-classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b4fdf61-4236-4537-a2e0-f6276041e1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f152f27-b307-4bb0-8ff4-1ec28b244be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   6.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   7.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   6.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   5.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   4.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   4.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   4.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   6.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   7.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   6.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   6.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   3.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   6.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   6.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   5.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   7.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   6.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   6.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   4.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   4.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   6.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   6.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   6.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   6.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   5.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   6.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   7.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   7.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   6.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   8.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   5.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   6.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   7.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   6.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   6.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   4.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   7.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   6.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   5.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   7.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   7.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   6.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   7.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   6.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   5.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   6.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   3.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   5.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   5.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   3.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   3.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   4.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   6.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   7.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   6.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   6.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   6.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   6.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   7.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   6.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   7.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   6.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   6.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   5.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   6.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   6.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   7.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   6.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   4.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   3.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   4.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   4.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   7.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   6.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   6.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   6.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   5.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   4.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   6.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   6.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   6.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   4.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   1.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   4.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   4.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   7.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   6.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   7.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   7.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   7.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   4.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   6.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   6.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   3.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   6.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   6.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   6.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   1.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   4.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   4.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   3.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   1.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   4.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   6.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   6.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   6.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   6.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   5.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   6.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   7.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   6.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   7.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   6.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   6.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   4.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   6.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   7.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   7.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   7.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   4.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   3.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   4.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   7.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   6.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   6.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   3.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   5.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   3.9s\n"
     ]
    }
   ],
   "source": [
    "# Tuned Decision Tree\n",
    "dt_clf = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    criterion='entropy',\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2\n",
    ")\n",
    "\n",
    "# Tuned Random Forest\n",
    "rf_clf = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=5,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0fd49e5-5189-4390-b9e8-9513ddf82219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;decision_tree&#x27;,\n",
       "                              DecisionTreeClassifier(criterion=&#x27;entropy&#x27;,\n",
       "                                                     random_state=42)),\n",
       "                             (&#x27;random_forest&#x27;,\n",
       "                              RandomForestClassifier(min_samples_split=5,\n",
       "                                                     n_estimators=200,\n",
       "                                                     n_jobs=-1,\n",
       "                                                     random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;VotingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.VotingClassifier.html\">?<span>Documentation for VotingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>VotingClassifier(estimators=[(&#x27;decision_tree&#x27;,\n",
       "                              DecisionTreeClassifier(criterion=&#x27;entropy&#x27;,\n",
       "                                                     random_state=42)),\n",
       "                             (&#x27;random_forest&#x27;,\n",
       "                              RandomForestClassifier(min_samples_split=5,\n",
       "                                                     n_estimators=200,\n",
       "                                                     n_jobs=-1,\n",
       "                                                     random_state=42))])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>decision_tree</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>random_forest</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(min_samples_split=5, n_estimators=200, n_jobs=-1,\n",
       "                       random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('decision_tree',\n",
       "                              DecisionTreeClassifier(criterion='entropy',\n",
       "                                                     random_state=42)),\n",
       "                             ('random_forest',\n",
       "                              RandomForestClassifier(min_samples_split=5,\n",
       "                                                     n_estimators=200,\n",
       "                                                     n_jobs=-1,\n",
       "                                                     random_state=42))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CREATE THE VOTING CLASSIFIER\n",
    "# List of (name, model) tuples\n",
    "estimators = [\n",
    "    ('decision_tree', dt_clf),\n",
    "    ('random_forest', rf_clf)\n",
    "]\n",
    "\n",
    "# Initialize the Voting Classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=estimators,\n",
    "    voting='hard'  # Use 'soft' if models have predict_proba method and you want to average probabilities\n",
    ")\n",
    "# Fit the model on the resampled training data\n",
    "voting_clf.fit(X_train_resampled, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e226248-af6b-42b2-9137-b39d675cde5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Accuracy: 0.7924318308291597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      518210       0.85      0.85      0.85       336\n",
      "      519100       0.89      0.86      0.88       358\n",
      "      541510       0.72      0.70      0.71       369\n",
      "      541600       0.59      0.68      0.63       361\n",
      "      541700       0.95      0.88      0.92       373\n",
      "\n",
      "    accuracy                           0.79      1797\n",
      "   macro avg       0.80      0.79      0.80      1797\n",
      "weighted avg       0.80      0.79      0.80      1797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_voting = voting_clf.predict(X_test_final)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Voting Classifier Accuracy: {accuracy_score(y_test_final, y_pred_voting)}\")\n",
    "print(classification_report(y_test_final, y_pred_voting))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8caac9d-22ef-4c4a-b90a-96bddd4d7680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Accuracy: 0.7835281023928771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      518210       0.85      0.83      0.84       336\n",
      "      519100       0.87      0.85      0.86       358\n",
      "      541510       0.70      0.68      0.69       369\n",
      "      541600       0.61      0.65      0.63       361\n",
      "      541700       0.91      0.90      0.90       373\n",
      "\n",
      "    accuracy                           0.78      1797\n",
      "   macro avg       0.79      0.78      0.79      1797\n",
      "weighted avg       0.79      0.78      0.78      1797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the base models\n",
    "base_models = [\n",
    "    ('decision_tree', DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_leaf=1, min_samples_split=2, random_state=42)),\n",
    "    ('random_forest', RandomForestClassifier(max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200, random_state=42, n_jobs=-1))\n",
    "]\n",
    "\n",
    "# Meta-model (commonly Logistic Regression)\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Initialize the StackingClassifier\n",
    "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5, n_jobs=-1)\n",
    "\n",
    "# Train the stacking classifier\n",
    "stacking_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_stacking = stacking_clf.predict(X_test_final)\n",
    "\n",
    "# Evaluate the Stacking Classifier\n",
    "print(f\"Stacking Classifier Accuracy: {accuracy_score(y_test_final, y_pred_stacking)}\")\n",
    "print(classification_report(y_test_final, y_pred_stacking))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e73cc1ae-c94c-4e6b-a008-26c7429d6857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier Accuracy: 0.8046744574290484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      518210       0.94      0.82      0.88       336\n",
      "      519100       0.92      0.88      0.90       358\n",
      "      541510       0.74      0.69      0.72       369\n",
      "      541600       0.58      0.71      0.64       361\n",
      "      541700       0.92      0.92      0.92       373\n",
      "\n",
      "    accuracy                           0.80      1797\n",
      "   macro avg       0.82      0.80      0.81      1797\n",
      "weighted avg       0.82      0.80      0.81      1797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize a Bagging Classifier with Decision Tree as the base estimator\n",
    "bagging_clf = BaggingClassifier(estimator=DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_leaf=1, min_samples_split=2, random_state=42),\n",
    "                                n_estimators=50, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Train the Bagging Classifier\n",
    "bagging_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_bagging = bagging_clf.predict(X_test_final)\n",
    "\n",
    "# Evaluate the Bagging Classifier\n",
    "print(f\"Bagging Classifier Accuracy: {accuracy_score(y_test_final, y_pred_bagging)}\")\n",
    "print(classification_report(y_test_final, y_pred_bagging))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741db1ac-274b-43a5-a19e-c0cb1424b68b",
   "metadata": {},
   "source": [
    "Results from Stacking and Bagging:\n",
    "Stacking Classifier: Accuracy: 78.35%\n",
    "The performance is similar to the individual models, though slightly lower than the tuned Decision Tree and Random Forest.\n",
    "Class 541600 shows a recall of 65% and precision of 61%, which is a modest improvement in recall but still lower in precision.\n",
    "\n",
    "Bagging Classifier: Accuracy: 80.47%\n",
    "This is on par with the best performance seen so far from the untuned Decision Tree (around 80.4%).\n",
    "Class 541600 has a recall of 71% and a precision of 58%, showing better recall but lower precision than in the other models.\n",
    "The overall performance across classes is solid, with Bagging improving stability in the model.\n",
    "\n",
    "Key Observations:\n",
    "The Bagging Classifier yielded the best results in terms of accuracy (similar to your earlier Decision Tree performance).\n",
    "Stacking didn’t provide a significant boost in performance, though it's still in a reasonable range.\n",
    "Class 541600 continues to be the hardest to predict, but the Bagging Classifier provided the best recall for this class.\n",
    "\n",
    "Next Steps:\n",
    "Consider Bagging: Since the Bagging Classifier gave the best results, it might be worth focusing on this model for final tuning or deployment.\n",
    "\n",
    "Further Fine-Tuning: You could try further fine-tuning the hyperparameters of the Bagging Classifier or explore variations like Random Forest with bagging or ExtraTreesClassifier.\n",
    "\n",
    "Explore Class Weights: If improving the prediction of class 541600 is critical, you might want to adjust the class weights to give more importance to the harder-to-predict classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24173101-ec20-48c6-adb0-0dff404f4b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Best parameters: {'estimator__max_depth': None, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 5, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 100}\n",
      "Best cross-validation score: 0.6112409571508068\n",
      "Fine-tuned Bagging Classifier Accuracy: 0.780189204229271\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      518210       0.89      0.80      0.84       336\n",
      "      519100       0.88      0.84      0.86       358\n",
      "      541510       0.71      0.66      0.69       369\n",
      "      541600       0.58      0.69      0.63       361\n",
      "      541700       0.89      0.91      0.90       373\n",
      "\n",
      "    accuracy                           0.78      1797\n",
      "   macro avg       0.79      0.78      0.78      1797\n",
      "weighted avg       0.79      0.78      0.78      1797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simplified parameter grid for faster tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],              # Reduce the number of base estimators to try\n",
    "    'max_samples': [0.75, 1.0],             # Focus on larger sample sizes\n",
    "    'max_features': [0.75, 1.0],            # Limit to fewer feature fractions\n",
    "    'estimator__max_depth': [None, 20],     # Use only a couple of max_depth values\n",
    "    'estimator__min_samples_split': [2, 5], # Fewer options for min_samples_split\n",
    "    'estimator__min_samples_leaf': [1, 2]   # Fewer options for min_samples_leaf\n",
    "}\n",
    "\n",
    "# Perform Grid Search with reduced parameter grid\n",
    "grid_search = GridSearchCV(bagging_clf, param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best parameters and score\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_}\")\n",
    "\n",
    "# Use the best model\n",
    "best_bagging_clf = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_best_bagging = best_bagging_clf.predict(X_test_final)\n",
    "\n",
    "# Evaluate the fine-tuned Bagging Classifier\n",
    "print(f\"Fine-tuned Bagging Classifier Accuracy: {accuracy_score(y_test_final, y_pred_best_bagging)}\")\n",
    "print(classification_report(y_test_final, y_pred_best_bagging))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98719f78-6825-4368-9cd6-50f35a1b0cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Classifier Accuracy: 0.8041179744017808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      518210       0.89      0.85      0.87       336\n",
      "      519100       0.92      0.88      0.90       358\n",
      "      541510       0.73      0.72      0.72       369\n",
      "      541600       0.59      0.68      0.63       361\n",
      "      541700       0.95      0.90      0.92       373\n",
      "\n",
      "    accuracy                           0.80      1797\n",
      "   macro avg       0.81      0.80      0.81      1797\n",
      "weighted avg       0.81      0.80      0.81      1797\n",
      "\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.6s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   1.7s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.7s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.8s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   3.1s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   2.0s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.7s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.8s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.2s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.5s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   4.7s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   6.6s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   1.9s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.9s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   4.9s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   5.7s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.2s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.7s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   3.2s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   2.9s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.6s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.6s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.4s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.8s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   5.6s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   6.4s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   2.1s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   4.1s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   5.2s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   5.8s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.4s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.5s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.5s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   2.8s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   5.6s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   1.8s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.6s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   5.0s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   3.7s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.3s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   2.2s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.4s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   5.0s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   6.1s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   2.0s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.7s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   5.0s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   5.8s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.2s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.8s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   3.3s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   2.9s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.7s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.6s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.2s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.8s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   4.6s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   5.6s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   1.9s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   4.2s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   5.5s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   7.3s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   2.1s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.9s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   4.8s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   3.0s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.6s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.3s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   2.0s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.5s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   4.7s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   5.5s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.1s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.5s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   2.9s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   2.5s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.1s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   1.8s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.5s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   4.8s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   6.4s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.4s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.7s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   3.3s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   3.1s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.6s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.2s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   1.9s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.8s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   5.4s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   5.7s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.2s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.6s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.5s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   2.8s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.9s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.7s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.4s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   2.0s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.6s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   5.4s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   3.6s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.8s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.5s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   2.3s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.7s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   4.7s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   5.9s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   1.9s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   4.1s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   4.7s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   5.7s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   1.9s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.9s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   4.5s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   3.9s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.5s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.0s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.9s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   3.6s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   3.3s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.6s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.4s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   1.9s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.3s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.4s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   3.1s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.8s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.6s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.6s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.1s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.9s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   4.8s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   6.5s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   1.8s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.5s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   5.0s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   5.5s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.3s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.7s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.9s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   3.5s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   2.0s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.8s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.7s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   2.3s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.7s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.6s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   2.9s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.7s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.6s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.5s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   1.9s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.6s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.5s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   2.9s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.6s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.6s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.6s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.2s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.5s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   4.4s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   3.7s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.5s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.1s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.6s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.6s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   3.0s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   6.0s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   2.2s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   4.0s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   4.8s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   6.1s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   2.1s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.9s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   5.0s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   3.3s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.7s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.0s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   1.9s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.5s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   4.4s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   5.6s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.3s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.8s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   3.7s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   3.3s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.8s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.8s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.5s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   4.1s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   4.7s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   6.0s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.2s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.9s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   3.2s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   2.9s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.4s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.3s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   1.8s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.4s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.2s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   2.8s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   3.7s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.5s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   1.8s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.9s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   5.2s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   3.5s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.6s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.3s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   2.0s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.4s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   4.7s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   5.8s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.4s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.6s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.6s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   3.1s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   5.9s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   1.9s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.8s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   4.6s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   3.0s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.6s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.4s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.8s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.8s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   3.1s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   6.5s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.5s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   4.0s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   3.1s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   2.9s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.5s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.6s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.2s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.7s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   4.8s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   6.2s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   1.9s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.5s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   4.4s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   2.3s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.3s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.9s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   5.5s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   6.1s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.3s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.6s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.5s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   2.8s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   5.6s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   2.1s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   4.0s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   5.1s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   6.0s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   2.1s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   4.0s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   4.5s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   6.2s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   2.0s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.6s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   5.9s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   6.5s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   2.4s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   4.5s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   4.6s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   6.4s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   2.0s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.7s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   5.0s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   5.5s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.1s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.6s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.4s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   2.6s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.6s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   1.8s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.6s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   5.1s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   6.9s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   2.0s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.6s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   4.8s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   3.0s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.6s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.1s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   2.0s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.5s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.7s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   2.9s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.8s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.7s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.4s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   1.9s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.4s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.3s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   2.8s\n",
      "[CV] END estimator__max_depth=None, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   5.5s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   2.1s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   2.1s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.5s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   5.3s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   6.5s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.6s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.9s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.5s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   2.8s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=1, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   5.8s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   2.0s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=0.75, max_samples=1.0, n_estimators=100; total time=   3.8s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   4.8s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=2, max_features=1.0, max_samples=1.0, n_estimators=50; total time=   2.9s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=50; total time=   1.6s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=0.75, n_estimators=100; total time=   3.1s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=0.75, max_samples=1.0, n_estimators=50; total time=   1.9s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=50; total time=   2.4s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=0.75, n_estimators=100; total time=   4.3s\n",
      "[CV] END estimator__max_depth=20, estimator__min_samples_leaf=2, estimator__min_samples_split=5, max_features=1.0, max_samples=1.0, n_estimators=100; total time=   4.0s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Initialize the Extra Trees Classifier\n",
    "extra_trees_clf = ExtraTreesClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Train the Extra Trees Classifier\n",
    "extra_trees_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_extra_trees = extra_trees_clf.predict(X_test_final)\n",
    "\n",
    "# Evaluate the Extra Trees Classifier\n",
    "print(f\"Extra Trees Classifier Accuracy: {accuracy_score(y_test_final, y_pred_extra_trees)}\")\n",
    "print(classification_report(y_test_final, y_pred_extra_trees))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b6d61d-baf6-473e-b2d2-d513f48e37f3",
   "metadata": {},
   "source": [
    "Key Observations:\n",
    "Extra Trees Classifier is performing slightly better than the fine-tuned Bagging Classifier (which had 78.0% accuracy).\n",
    "Class-Specific Performance:\n",
    "518210 and 519100: These classes have high precision and recall, similar to previous models.\n",
    "541510: Performance is steady with a good F1-score of 0.72.\n",
    "541600: Recall has improved slightly (68%), while precision is stable at 59%.\n",
    "Comparison:\n",
    "Model\tAccuracy\tMacro Avg Precision\tMacro Avg Recall\tBest Class (F1)\t541600 (F1)\n",
    "Bagging Classifier (tuned)\t78.0%\t0.79\t0.78\t541700 (0.90)\t0.63\n",
    "Extra Trees Classifier\t80.41%\t0.81\t0.80\t541700 (0.92)\t0.63\n",
    "Conclusion:\n",
    "Extra Trees Classifier seems to be the strongest model so far, with the highest accuracy and well-balanced performance across most classes.\n",
    "Class 541600 still has lower precision but better recall, which is a typical challenge in class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fda907ed-51f0-4e6b-943d-3770b0ef1d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['extra_trees_model.pkl']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FINALIZE EXTRA TREES CLASSIFIER:\n",
    "import joblib\n",
    "\n",
    "# Finalize the Extra Trees model (already trained)\n",
    "joblib.dump(extra_trees_clf, 'extra_trees_model.pkl')  # Save the model\n",
    "\n",
    "# To load the model later for predictions\n",
    "# extra_trees_clf = joblib.load('extra_trees_model.pkl')\n",
    "\n",
    "# Predicting NAICS on new data (e.g., X_new)\n",
    "# y_pred_naics = extra_trees_clf.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32495acd-08bb-4ed0-a3e1-b3f8fb729154",
   "metadata": {},
   "source": [
    "KMEANS     WE WANT TO APPLY KMEANS CLUSTERING ON LOCATION DATA \n",
    "To predict business locations, we’ll use KMeans to cluster the geographic coordinates (latitude, longitude). This will help group locations where similar types of businesses might cluster.\n",
    "\n",
    "Using KMeans clustering could indeed help with predicting locations of NAICS codes, especially if your goal is to group similar businesses or predict where certain business activities (NAICS codes) are likely to cluster based on geographic features like latitude, longitude, or other relevant data.\n",
    "\n",
    "How KMeans Clustering Can Help with Location Prediction:\n",
    "Identifying Business Clusters by Location:\n",
    "\n",
    "KMeans can group businesses based on geographic coordinates (latitude and longitude) and other features like business type (NAICS codes). This helps identify natural groupings of businesses by location, such as tech clusters in certain areas of a city.\n",
    "Predicting Future Locations:\n",
    "\n",
    "By analyzing the clusters formed by KMeans, you might observe patterns, such as certain types of businesses clustering around specific geographic regions. This can be helpful in predicting where future businesses (based on NAICS codes) might emerge.\n",
    "Combining Geospatial and Business Data:\n",
    "\n",
    "KMeans can be applied using both location data (latitude and longitude) and business characteristics (like NAICS codes, revenue, or size) to cluster similar businesses geographically. These clusters could be used to predict future locations of business\n",
    "\n",
    "\n",
    "Steps:\n",
    "Cluster Locations using KMeans on your geographic data (latitude, longitude).\n",
    "Analyze Clusters: Understand which clusters are likely to contain certain NAICS codes.\n",
    "Predict Future Business Locations by using the combination of KMeans clusters and NAICS predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "02aab896-20a1-4725-a24a-63587575d5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   latitude  longitude\n",
      "0   34.0189  -118.4195\n",
      "1   34.0252  -118.4194\n",
      "2   34.0392  -118.3954\n",
      "3   34.0404  -118.3733\n",
      "4   34.0182  -118.4185\n"
     ]
    }
   ],
   "source": [
    "# Extract the latitude and longitude as separate columns\n",
    "merged_data_with_pca['latitude'] = merged_data_with_pca['LOCATION'].str.extract(r'\\((.*),')[0].astype(float)\n",
    "merged_data_with_pca['longitude'] = merged_data_with_pca['LOCATION'].str.extract(r',\\s*(.*)\\)')[0].astype(float)\n",
    "\n",
    "# Verify the extraction\n",
    "print(merged_data_with_pca[['latitude', 'longitude']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2202898a-62f6-411c-85c5-f076404d252a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitude     112\n",
      "longitude    112\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values in latitude and longitude columns\n",
    "print(merged_data_with_pca[['latitude', 'longitude']].isnull().sum())\n",
    "\n",
    "# Option 1: Drop rows with NaN values\n",
    "merged_data_with_pca = merged_data_with_pca.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "# Option 2: Impute missing values (if dropping isn't desired)\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# imputer = SimpleImputer(strategy='mean')  # You can also use 'median'\n",
    "# merged_data_with_pca[['latitude', 'longitude']] = imputer.fit_transform(merged_data_with_pca[['latitude', 'longitude']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7e58b29-1ef2-491f-8f66-84751c94ecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "617f69ce-2f12-4014-a8d0-055a3939b2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained Extra Trees model\n",
    "extra_trees_clf = joblib.load('extra_trees_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a87a35f-2595-4bc0-941c-d9f8235b628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "merged_data_with_pca = pd.read_csv('merged_data_with_pca.csv')  # Adjust to the correct path and file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29682c93-ce01-4062-bd5a-9c0d8c750e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   latitude  longitude\n",
      "0   34.0189  -118.4195\n",
      "1   34.0252  -118.4194\n",
      "2   34.0392  -118.3954\n",
      "3   34.0404  -118.3733\n",
      "4   34.0182  -118.4185\n"
     ]
    }
   ],
   "source": [
    "# Extract latitude and longitude from the 'LOCATION' column\n",
    "merged_data_with_pca['latitude'] = merged_data_with_pca['LOCATION'].str.extract(r'\\((.*),')[0].astype(float)\n",
    "merged_data_with_pca['longitude'] = merged_data_with_pca['LOCATION'].str.extract(r',\\s*(.*)\\)')[0].astype(float)\n",
    "\n",
    "# Verify the extraction\n",
    "print(merged_data_with_pca[['latitude', 'longitude']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b27628f-0d31-4414-bbe0-a8caa8fdb000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitude     112\n",
      "longitude    112\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "print(merged_data_with_pca[['latitude', 'longitude']].isnull().sum())\n",
    "\n",
    "# Option 1: Drop rows with missing values\n",
    "merged_data_with_pca = merged_data_with_pca.dropna(subset=['latitude', 'longitude'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e360209a-2b7d-4188-bcb9-a72709b6ee77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitude     0\n",
      "longitude    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Impute missing latitude and longitude values with the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "merged_data_with_pca[['latitude', 'longitude']] = imputer.fit_transform(merged_data_with_pca[['latitude', 'longitude']])\n",
    "\n",
    "# Verify that there are no missing values\n",
    "print(merged_data_with_pca[['latitude', 'longitude']].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca8385bc-e107-482a-87ba-2932c6e6d6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geo_cluster\n",
      "3    1641\n",
      "1     977\n",
      "4     460\n",
      "0     263\n",
      "2      18\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Use latitude and longitude for clustering\n",
    "geo_data = merged_data_with_pca[['latitude', 'longitude']]\n",
    "\n",
    "# Apply KMeans to group locations into clusters (adjust n_clusters as needed)\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "geo_clusters = kmeans.fit_predict(geo_data)\n",
    "\n",
    "# Add the cluster labels to the dataset\n",
    "merged_data_with_pca['geo_cluster'] = geo_clusters\n",
    "\n",
    "# Analyze the cluster distribution\n",
    "print(merged_data_with_pca['geo_cluster'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075eca09-466c-429a-8daa-bbe64e1a47df",
   "metadata": {},
   "source": [
    "The KMeans clustering has successfully grouped your data into five clusters, with the following distribution of businesses across the clusters:\n",
    "\n",
    "Cluster 3: 1641 locations\n",
    "Cluster 1: 977 locations\n",
    "Cluster 4: 460 locations\n",
    "Cluster 0: 263 locations\n",
    "Cluster 2: 18 locations\n",
    "Next Steps:\n",
    "Now that you have the clusters, you can proceed with analyzing the predicted NAICS codes within each cluster to gain insights into the types of businesses located in each geographic region.\n",
    "\n",
    "Step 1: Analyze NAICS Codes by Cluster\n",
    "Let’s group the data by the geo_cluster and see the distribution of predicted NAICS codes within each cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d64915e-82ce-4472-9845-5d752f07f31f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: predicted_naics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Analyze the distribution of NAICS codes within each cluster\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m naics_cluster_distribution \u001b[38;5;241m=\u001b[39m merged_data_with_pca\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeo_cluster\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_naics\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(naics_cluster_distribution)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/generic.py:1951\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1945\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[1;32m   1946\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1950\u001b[0m     )\n\u001b[0;32m-> 1951\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(key)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/base.py:244\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[0;32m--> 244\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    245\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key]\u001b[38;5;241m.\u001b[39mndim\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39mndim)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column not found: predicted_naics'"
     ]
    }
   ],
   "source": [
    "# Analyze the distribution of NAICS codes within each cluster\n",
    "naics_cluster_distribution = merged_data_with_pca.groupby('geo_cluster')['predicted_naics'].value_counts()\n",
    "print(naics_cluster_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d59144c1-afe8-4e4b-a003-a53869208ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   predicted_naics\n",
      "0           541510\n",
      "1           541510\n",
      "2           541510\n",
      "3           541510\n",
      "4           541510\n"
     ]
    }
   ],
   "source": [
    "# Ensure you have loaded the Extra Trees Classifier model\n",
    "# If not, load the trained model (if you have saved it previously)\n",
    "# extra_trees_clf = joblib.load('extra_trees_model.pkl')\n",
    "\n",
    "# Predict NAICS codes using the trained Extra Trees Classifier\n",
    "y_pred_naics = extra_trees_clf.predict(merged_data_with_pca[['PC1', 'PC2', 'PC3', 'PC4', 'PC5']])\n",
    "\n",
    "# Add NAICS predictions to the dataset\n",
    "merged_data_with_pca['predicted_naics'] = y_pred_naics\n",
    "\n",
    "# Verify that the 'predicted_naics' column has been added\n",
    "print(merged_data_with_pca[['predicted_naics']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76f1f5a0-21c8-405c-bd02-6d5db9561d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geo_cluster  predicted_naics\n",
      "0            541600              138\n",
      "             541510               71\n",
      "             518210               25\n",
      "             519100               24\n",
      "             541700                5\n",
      "1            541600              624\n",
      "             541510              255\n",
      "             519100               45\n",
      "             518210               35\n",
      "             541700               18\n",
      "2            541600               12\n",
      "             541510                4\n",
      "             518210                1\n",
      "             519100                1\n",
      "3            541600             1077\n",
      "             541510              326\n",
      "             518210              120\n",
      "             519100               79\n",
      "             541700               39\n",
      "4            541600              265\n",
      "             541510               93\n",
      "             518210               47\n",
      "             519100               34\n",
      "             541700               21\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Analyze the distribution of predicted NAICS codes within each cluster\n",
    "naics_cluster_distribution = merged_data_with_pca.groupby('geo_cluster')['predicted_naics'].value_counts()\n",
    "print(naics_cluster_distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910373c7-b1c8-4e33-a1d2-2bcca015f8c9",
   "metadata": {},
   "source": [
    "Insights:\n",
    "541600 (Management, Scientific, & Technical Consulting Services) is the most dominant business type across all clusters, especially in Cluster 3 and Cluster 1.\n",
    "541510 (Computer Systems Design Services) is the second most prevalent business type across the clusters.\n",
    "Cluster 2 is the smallest, with a relatively small number of businesses.\n",
    "Clusters 3 and 1 are the largest and seem to attract more diverse types of businesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70c32102-fdb0-4aa8-b81b-576fd73c4b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['extra_trees_model.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SAVE CLUSTERS AND EXTRA TREE MODEL NOW!!\n",
    "\n",
    "# Save the dataset to a CSV file\n",
    "merged_data_with_pca.to_csv('merged_data_with_clusters_and_naics.csv', index=False)\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Save the trained Extra Trees model\n",
    "joblib.dump(extra_trees_clf, 'extra_trees_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3dc79659-00be-41cb-a135-2556bacb049e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kmeans_model.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the KMeans model\n",
    "joblib.dump(kmeans, 'kmeans_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26081187-7e62-46db-809b-1f8bd19a5238",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION\n",
    "\n",
    "How to Incorporate Logistic Regression:\n",
    "Predict NAICS Codes using Logistic Regression based on your features (PC1, PC2, etc.).\n",
    "Compare the performance of Logistic Regression with Extra Trees Classifier (or any other model) to see which performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f05e4f66-4a07-4487-be80-3693968a2639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6299493896993152\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      518210       0.00      0.00      0.00       228\n",
      "      519100       0.00      0.00      0.00       183\n",
      "      541510       0.00      0.00      0.00       749\n",
      "      541600       0.63      1.00      0.77      2116\n",
      "      541700       0.00      0.00      0.00        83\n",
      "\n",
      "    accuracy                           0.63      3359\n",
      "   macro avg       0.13      0.20      0.15      3359\n",
      "weighted avg       0.40      0.63      0.49      3359\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/admin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/admin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Prepare features and target for Logistic Regression\n",
    "X = merged_data_with_pca[['PC1', 'PC2', 'PC3', 'PC4', 'PC5']]\n",
    "y = merged_data_with_pca['predicted_naics']\n",
    "\n",
    "# Initialize and fit the logistic regression model\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_logreg = logreg.predict(X)\n",
    "\n",
    "# Evaluate the logistic regression model\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_score(y, y_pred_logreg)}\")\n",
    "print(classification_report(y, y_pred_logreg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aea7cd6-bf68-44a2-b9a7-401af19a5398",
   "metadata": {},
   "source": [
    "VALIDATION\n",
    "\n",
    "Historical Validation of Model Predictions\n",
    "To validate the model’s predictive ability, we will perform a historical analysis using data from 2010 to 2015 as the training period and data from 2016 to 2020 for validation. The goal was to assess how well the model could predict the growth of tech companies (by NAICS codes) over the test period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05b87fef-013b-469f-93d0-1db613cf9023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['BUSINESS NAME', 'ZIP CODE', 'NAICS', 'LOCATION START DATE',\n",
      "       'LOCATION END DATE', 'LOCATION', 'PRIMARY NAICS DESCRIPTION',\n",
      "       'Pop 18-24 Some College', 'Pop 18-24 Bachelors+', 'Pop 25-34 HS+',\n",
      "       'Pop 25-34 Bachelors+', 'Pop 35-44 HS+', 'Pop 35-44 Bachelors+',\n",
      "       'Pop 45-64 HS+', 'Pop 45-64 Bachelors+', 'Pop 65+ HS+',\n",
      "       'Pop 65+ Bachelors+', 'ZipCode', 'Year'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BUSINESS NAME</th>\n",
       "      <th>ZIP CODE</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>LOCATION START DATE</th>\n",
       "      <th>LOCATION END DATE</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>PRIMARY NAICS DESCRIPTION</th>\n",
       "      <th>Pop 18-24 Some College</th>\n",
       "      <th>Pop 18-24 Bachelors+</th>\n",
       "      <th>Pop 25-34 HS+</th>\n",
       "      <th>Pop 25-34 Bachelors+</th>\n",
       "      <th>Pop 35-44 HS+</th>\n",
       "      <th>Pop 35-44 Bachelors+</th>\n",
       "      <th>Pop 45-64 HS+</th>\n",
       "      <th>Pop 45-64 Bachelors+</th>\n",
       "      <th>Pop 65+ HS+</th>\n",
       "      <th>Pop 65+ Bachelors+</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUSAN K TENNER</td>\n",
       "      <td>90034-6505</td>\n",
       "      <td>541600.0</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(34.0189, -118.4195)</td>\n",
       "      <td>Management, scientific, &amp; technical consulting...</td>\n",
       "      <td>1778</td>\n",
       "      <td>1462</td>\n",
       "      <td>15919</td>\n",
       "      <td>11537</td>\n",
       "      <td>8941</td>\n",
       "      <td>5626</td>\n",
       "      <td>9463</td>\n",
       "      <td>4958</td>\n",
       "      <td>4225</td>\n",
       "      <td>2207</td>\n",
       "      <td>90034</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROBERT D KAMINSKI JR</td>\n",
       "      <td>90034-3001</td>\n",
       "      <td>541600.0</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(34.0252, -118.4194)</td>\n",
       "      <td>Management, scientific, &amp; technical consulting...</td>\n",
       "      <td>1778</td>\n",
       "      <td>1462</td>\n",
       "      <td>15919</td>\n",
       "      <td>11537</td>\n",
       "      <td>8941</td>\n",
       "      <td>5626</td>\n",
       "      <td>9463</td>\n",
       "      <td>4958</td>\n",
       "      <td>4225</td>\n",
       "      <td>2207</td>\n",
       "      <td>90034</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANDREW LEVEY</td>\n",
       "      <td>90034-1816</td>\n",
       "      <td>541600.0</td>\n",
       "      <td>11/30/2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(34.0392, -118.3954)</td>\n",
       "      <td>Management, scientific, &amp; technical consulting...</td>\n",
       "      <td>1778</td>\n",
       "      <td>1462</td>\n",
       "      <td>15919</td>\n",
       "      <td>11537</td>\n",
       "      <td>8941</td>\n",
       "      <td>5626</td>\n",
       "      <td>9463</td>\n",
       "      <td>4958</td>\n",
       "      <td>4225</td>\n",
       "      <td>2207</td>\n",
       "      <td>90034</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JOHANNES SAAM</td>\n",
       "      <td>90034-1612</td>\n",
       "      <td>541510.0</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(34.0404, -118.3733)</td>\n",
       "      <td>Computer systems design &amp; related services</td>\n",
       "      <td>1778</td>\n",
       "      <td>1462</td>\n",
       "      <td>15919</td>\n",
       "      <td>11537</td>\n",
       "      <td>8941</td>\n",
       "      <td>5626</td>\n",
       "      <td>9463</td>\n",
       "      <td>4958</td>\n",
       "      <td>4225</td>\n",
       "      <td>2207</td>\n",
       "      <td>90034</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MELISSA SATO</td>\n",
       "      <td>90034-6108</td>\n",
       "      <td>541700.0</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(34.0182, -118.4185)</td>\n",
       "      <td>Scientific research &amp; development services</td>\n",
       "      <td>1778</td>\n",
       "      <td>1462</td>\n",
       "      <td>15919</td>\n",
       "      <td>11537</td>\n",
       "      <td>8941</td>\n",
       "      <td>5626</td>\n",
       "      <td>9463</td>\n",
       "      <td>4958</td>\n",
       "      <td>4225</td>\n",
       "      <td>2207</td>\n",
       "      <td>90034</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          BUSINESS NAME    ZIP CODE     NAICS LOCATION START DATE  \\\n",
       "0        SUSAN K TENNER  90034-6505  541600.0          01/01/2019   \n",
       "1  ROBERT D KAMINSKI JR  90034-3001  541600.0          01/01/2019   \n",
       "2          ANDREW LEVEY  90034-1816  541600.0          11/30/2019   \n",
       "3         JOHANNES SAAM  90034-1612  541510.0          01/01/2019   \n",
       "4          MELISSA SATO  90034-6108  541700.0          01/01/2019   \n",
       "\n",
       "   LOCATION END DATE              LOCATION  \\\n",
       "0                NaN  (34.0189, -118.4195)   \n",
       "1                NaN  (34.0252, -118.4194)   \n",
       "2                NaN  (34.0392, -118.3954)   \n",
       "3                NaN  (34.0404, -118.3733)   \n",
       "4                NaN  (34.0182, -118.4185)   \n",
       "\n",
       "                           PRIMARY NAICS DESCRIPTION  Pop 18-24 Some College  \\\n",
       "0  Management, scientific, & technical consulting...                    1778   \n",
       "1  Management, scientific, & technical consulting...                    1778   \n",
       "2  Management, scientific, & technical consulting...                    1778   \n",
       "3         Computer systems design & related services                    1778   \n",
       "4         Scientific research & development services                    1778   \n",
       "\n",
       "   Pop 18-24 Bachelors+  Pop 25-34 HS+  Pop 25-34 Bachelors+  Pop 35-44 HS+  \\\n",
       "0                  1462          15919                 11537           8941   \n",
       "1                  1462          15919                 11537           8941   \n",
       "2                  1462          15919                 11537           8941   \n",
       "3                  1462          15919                 11537           8941   \n",
       "4                  1462          15919                 11537           8941   \n",
       "\n",
       "   Pop 35-44 Bachelors+  Pop 45-64 HS+  Pop 45-64 Bachelors+  Pop 65+ HS+  \\\n",
       "0                  5626           9463                  4958         4225   \n",
       "1                  5626           9463                  4958         4225   \n",
       "2                  5626           9463                  4958         4225   \n",
       "3                  5626           9463                  4958         4225   \n",
       "4                  5626           9463                  4958         4225   \n",
       "\n",
       "   Pop 65+ Bachelors+  ZipCode  Year  \n",
       "0                2207    90034  2019  \n",
       "1                2207    90034  2019  \n",
       "2                2207    90034  2019  \n",
       "3                2207    90034  2019  \n",
       "4                2207    90034  2019  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STEP ONE - LOAD DATA\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('filtered_data_final_no_scaling.csv')\n",
    "\n",
    "# Check the structure of the data\n",
    "print(data.columns)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43b62a5e-c2e5-4455-96a9-baa093f237bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (1349, 19)\n",
      "Test data: (2146, 19)\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Split the Data Temporally\n",
    "# Split the data into training (up to 2015) and test (after 2015)\n",
    "training_data = data[data['Year'] <= 2015]  # Training data up to 2015\n",
    "test_data = data[data['Year'] > 2015]       # Test data after 2015 (2016-2020)\n",
    "\n",
    "# Check the sizes of the datasets\n",
    "print(f\"Training data: {training_data.shape}\")\n",
    "print(f\"Test data: {test_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c298005-e199-4707-b912-653f55bed689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in NAICS column: 11\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the target column (NAICS)\n",
    "print(f\"Missing values in NAICS column: {training_data['NAICS'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64c204c0-84af-431a-a1ca-551b54d17122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining missing values in training set NAICS: 0\n",
      "Remaining missing values in test set NAICS: 0\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where NAICS is missing in both training and test data\n",
    "training_data = training_data.dropna(subset=['NAICS'])\n",
    "test_data = test_data.dropna(subset=['NAICS'])\n",
    "\n",
    "# Now re-check the number of missing values\n",
    "print(f\"Remaining missing values in training set NAICS: {training_data['NAICS'].isnull().sum()}\")\n",
    "print(f\"Remaining missing values in test set NAICS: {test_data['NAICS'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5be72613-d562-4607-9bb6-301d2aa14225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExtraTreesClassifier(min_samples_split=5, n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;ExtraTreesClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html\">?<span>Documentation for ExtraTreesClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>ExtraTreesClassifier(min_samples_split=5, n_estimators=200)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "ExtraTreesClassifier(min_samples_split=5, n_estimators=200)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Extract features and target from training data\n",
    "X_train = training_data.drop(['NAICS', 'Year', 'BUSINESS NAME', 'ZIP CODE', 'LOCATION START DATE', 'LOCATION END DATE', 'LOCATION', 'PRIMARY NAICS DESCRIPTION'], axis=1)\n",
    "y_train = training_data['NAICS']  # Target (NAICS codes)\n",
    "\n",
    "# Initialize and train the Extra Trees model\n",
    "et_model = ExtraTreesClassifier(n_estimators=200, max_depth=None, min_samples_split=5, min_samples_leaf=1)\n",
    "et_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "def8f52c-433c-40b6-b078-24ee1d9e8e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from the cleaned test data\n",
    "X_test = test_data.drop(['NAICS', 'Year', 'BUSINESS NAME', 'ZIP CODE', 'LOCATION START DATE', 'LOCATION END DATE', 'LOCATION', 'PRIMARY NAICS DESCRIPTION'], axis=1)\n",
    "y_test = test_data['NAICS']  # Actual NAICS codes (target)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = et_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27ed7579-f872-44a1-a298-32e973bbb4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.08\n",
      "Recall: 0.10\n",
      "F1-Score: 0.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Evaluate the model's performance\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "817088a1-683f-47b4-b8cf-f7c2c03ee7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAICS\n",
      "541600.0    873\n",
      "541510.0    261\n",
      "518210.0     85\n",
      "519100.0     79\n",
      "541700.0     40\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of NAICS codes in the training set\n",
    "print(training_data['NAICS'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62a733eb-b939-496d-b185-b2611d821866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.59\n",
      "Recall: 0.09\n",
      "F1-Score: 0.06\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Initialize and train the Extra Trees model with class weights\n",
    "et_model = ExtraTreesClassifier(n_estimators=200, max_depth=None, min_samples_split=5, min_samples_leaf=1, class_weight=\"balanced\")\n",
    "et_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = et_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "recall = recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "f1 = f1_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66f6ec4-6077-45dd-a3ec-1ea701fb92d1",
   "metadata": {},
   "source": [
    "Here’s what these metrics tell us:\n",
    "\n",
    "Precision (0.60): When my model predicts a particular NAICS code, it’s correct 60% of the time.\n",
    "Recall (0.09): My model is only capturing 9% of the actual instances of the underrepresented classes.\n",
    "F1-Score (0.06): The harmonic mean of precision and recall is still quite low, which means the model's overall balance between precision and recall is not great.\n",
    "\n",
    "LETS APPLY SMOTE NOW TO INCREASE OUR RECALL (Oversampling)\n",
    "Oversampling the minority classes can help increase the recall by providing the model with more training examples for the underrepresented classes. We’ll combine this with class weighting to address the class imbalance more aggressively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "622dc177-305b-46ce-800c-f64900c5bbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.59\n",
      "Recall: 0.10\n",
      "F1-Score: 0.04\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Apply SMOTE to the training data to balance the classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train the Extra Trees model with class weights on the resampled data\n",
    "et_model = ExtraTreesClassifier(n_estimators=200, max_depth=None, min_samples_split=5, min_samples_leaf=1, class_weight=\"balanced\")\n",
    "et_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = et_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "recall = recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "f1 = f1_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4448e8a6-f62a-4891-b340-2054e5f49cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.58\n",
      "Recall: 0.09\n",
      "F1-Score: 0.04\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "# Apply a combination of SMOTE and Edited Nearest Neighbors (SMOTEENN)\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train the model on the resampled data\n",
    "et_model = ExtraTreesClassifier(n_estimators=200, max_depth=None, min_samples_split=5, min_samples_leaf=1, class_weight=\"balanced\")\n",
    "et_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = et_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "recall = recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "f1 = f1_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eeb89c95-4458-47cb-88cd-e38d175b898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_model = ExtraTreesClassifier(n_estimators=500, max_depth=None, min_samples_split=5, min_samples_leaf=1, class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dcfdc1c-dbc9-429c-b338-2632c29a5452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.58\n",
      "Recall: 0.08\n",
      "F1-Score: 0.04\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Set up the randomized search\n",
    "random_search = RandomizedSearchCV(estimator=et_model, param_distributions=param_grid, n_iter=10, cv=3, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Use the best model\n",
    "best_et_model = random_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_et_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "recall = recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "f1 = f1_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7312c7e-bf08-4d33-91eb-4df7525f9386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.59\n",
      "Recall: 0.09\n",
      "F1-Score: 0.04\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Set up the grid search\n",
    "grid_search = GridSearchCV(estimator=et_model, param_grid=param_grid, cv=3, n_jobs=-1, scoring='f1_macro')\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Use the best model found by GridSearchCV\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "recall = recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "f1 = f1_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c62a458-9442-4808-b420-dce960f347d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.63\n",
      "Recall: 0.09\n",
      "F1-Score: 0.04\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the training and test data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Re-train the Logistic Regression model with scaled data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "recall = recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "f1 = f1_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57ab2110-1898-45cf-954d-0893e5c0269e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n",
      "0.12.3\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import imblearn\n",
    "\n",
    "print(sklearn.__version__)  # should be the latest version, e.g., 1.0.2 or newer\n",
    "print(imblearn.__version__)  # should be the latest version, e.g., 0.9.0 or newer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9df7082-8b82-4a42-b56d-561fd4691a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (1338, 11)\n",
      "Shape of y_train: (1338,)\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes of X_train and y_train before scaling\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c521941-c234-47cc-aab2-00c50f276484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_scaled: (4365, 11)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of X_train_scaled: {X_train_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2e59706-c85c-46d7-b24a-c31102b83826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_resampled: (4365, 11)\n",
      "Shape of y_train_resampled: (4365,)\n"
     ]
    }
   ],
   "source": [
    "# Resample the data (if using SMOTE or any resampling technique)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Now, check the shape of the resampled data\n",
    "print(f\"Shape of X_train_resampled: {X_train_resampled.shape}\")\n",
    "print(f\"Shape of y_train_resampled: {y_train_resampled.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04853f69-74ae-482f-b333-9808998c341c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_resampled_scaled: (4365, 11)\n"
     ]
    }
   ],
   "source": [
    "# Scale the resampled data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the resampled training data\n",
    "X_train_resampled_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)  # Test data should also be scaled, but not resampled\n",
    "\n",
    "# Confirm the shape of the scaled resampled data\n",
    "print(f\"Shape of X_train_resampled_scaled: {X_train_resampled_scaled.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bd5a45b-d63e-40e3-8af6-422d67ebb467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.59\n",
      "Recall: 0.10\n",
      "F1-Score: 0.04\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Train the Balanced Random Forest model with updated parameters\n",
    "brf_model = BalancedRandomForestClassifier(n_estimators=200, random_state=42,\n",
    "                                           sampling_strategy='all',  # Future default\n",
    "                                           replacement=True,         # Future default\n",
    "                                           bootstrap=False)           # Future default\n",
    "brf_model.fit(X_train_resampled_scaled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = brf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "recall = recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "f1 = f1_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0cadfd2c-68a4-4ddb-816b-a68c5e95bd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.83\n",
      "Recall: 0.17\n",
      "F1-Score: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Adjust the threshold (e.g., lower to 0.2 or 0.1)\n",
    "threshold = 0.2  # You can try different values like 0.1, 0.15, etc.\n",
    "y_pred_adjusted = (y_probs[:, 1] >= threshold).astype(int)\n",
    "\n",
    "# Evaluate the adjusted model\n",
    "precision = precision_score(y_test, y_pred_adjusted, average='macro', zero_division=1)\n",
    "recall = recall_score(y_test, y_pred_adjusted, average='macro', zero_division=1)\n",
    "f1 = f1_score(y_test, y_pred_adjusted, average='macro', zero_division=1)\n",
    "\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a7b82d06-9f15-4270-9286-e348bb1a40c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered X_test shape: (2127, 11)\n",
      "Filtered y_test shape: (2127,)\n"
     ]
    }
   ],
   "source": [
    "# Get the unique labels from y_train_resampled\n",
    "train_labels = set(le.classes_)\n",
    "\n",
    "# Create a mask to filter out rows with unseen labels in y_test\n",
    "mask = y_test.isin(train_labels)\n",
    "\n",
    "# Filter the test set based on the mask\n",
    "X_test_filtered = X_test_scaled[mask]\n",
    "y_test_filtered = y_test[mask]\n",
    "\n",
    "# Now encode the filtered test labels\n",
    "y_test_encoded = le.transform(y_test_filtered)\n",
    "\n",
    "# Check the shape of filtered test data to verify\n",
    "print(f\"Filtered X_test shape: {X_test_filtered.shape}\")\n",
    "print(f\"Filtered y_test shape: {y_test_filtered.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fe739a29-85b8-4609-8bbf-a1343420916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Create DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train_resampled_scaled, label=y_train_resampled_encoded)\n",
    "dtest = xgb.DMatrix(X_test_filtered, label=y_test_encoded)\n",
    "\n",
    "# Set XGBoost parameters for imbalanced data\n",
    "params = {\n",
    "    'objective': 'multi:softprob',  # For probability output\n",
    "    'num_class': len(np.unique(y_train_resampled_encoded)),  # Number of unique classes\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.1\n",
    "}\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_model = xgb.train(params, dtrain, num_boost_round=200)\n",
    "\n",
    "# Make predictions on the filtered test set\n",
    "y_pred_probs = xgb_model.predict(dtest)\n",
    "\n",
    "# Adjust the threshold (e.g., 0.3)\n",
    "y_pred_adjusted = (y_pred_probs[:, 1] >= 0.3).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "30f54640-4e62-424b-acb9-4f5cf6fa2dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Precision: 0.62\n",
      "XGBoost Recall: 0.19\n",
      "XGBoost F1-Score: 0.04\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Evaluate the model's performance\n",
    "precision = precision_score(y_test_encoded, y_pred_adjusted, average='macro', zero_division=1)\n",
    "recall = recall_score(y_test_encoded, y_pred_adjusted, average='macro', zero_division=1)\n",
    "f1 = f1_score(y_test_encoded, y_pred_adjusted, average='macro', zero_division=1)\n",
    "\n",
    "print(f'XGBoost Precision: {precision:.2f}')\n",
    "print(f'XGBoost Recall: {recall:.2f}')\n",
    "print(f'XGBoost F1-Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7243dfc8-9559-4a4e-ac4c-0821cce2b952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Precision: 0.62\n",
      "XGBoost Recall: 0.19\n",
      "XGBoost F1-Score: 0.04\n"
     ]
    }
   ],
   "source": [
    "# Adjust the threshold further (e.g., to 0.2 or 0.1)\n",
    "threshold = 0.1  # Try different values like 0.1 or 0.15\n",
    "y_pred_adjusted = (y_pred_probs[:, 1] >= threshold).astype(int)\n",
    "\n",
    "# Re-evaluate with the new threshold\n",
    "precision = precision_score(y_test_encoded, y_pred_adjusted, average='macro', zero_division=1)\n",
    "recall = recall_score(y_test_encoded, y_pred_adjusted, average='macro', zero_division=1)\n",
    "f1 = f1_score(y_test_encoded, y_pred_adjusted, average='macro', zero_division=1)\n",
    "\n",
    "print(f'XGBoost Precision: {precision:.2f}')\n",
    "print(f'XGBoost Recall: {recall:.2f}')\n",
    "print(f'XGBoost F1-Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d07f6de3-1d33-4e93-abaa-dd657eb0d558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned XGBoost Precision: 0.62\n",
      "Tuned XGBoost Recall: 0.20\n",
      "Tuned XGBoost F1-Score: 0.04\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define the model\n",
    "xgb_model = XGBClassifier(objective='multi:softprob', num_class=len(np.unique(y_train_resampled_encoded)))\n",
    "\n",
    "# Define the hyperparameters grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='f1_macro', cv=3, n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train_resampled_scaled, y_train_resampled_encoded)\n",
    "\n",
    "# Best model from GridSearch\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred_probs = best_xgb_model.predict_proba(X_test_filtered)\n",
    "\n",
    "# Adjust the threshold\n",
    "y_pred_adjusted = (y_pred_probs[:, 1] >= 0.3).astype(int)\n",
    "\n",
    "# Re-evaluate with the tuned model\n",
    "precision = precision_score(y_test_encoded, y_pred_adjusted, average='macro', zero_division=1)\n",
    "recall = recall_score(y_test_encoded, y_pred_adjusted, average='macro', zero_division=1)\n",
    "f1 = f1_score(y_test_encoded, y_pred_adjusted, average='macro', zero_division=1)\n",
    "\n",
    "print(f'Tuned XGBoost Precision: {precision:.2f}')\n",
    "print(f'Tuned XGBoost Recall: {recall:.2f}')\n",
    "print(f'Tuned XGBoost F1-Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4b6039d5-4d65-4f8c-b3ff-2c69f3f74279",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': len(np.unique(y_train_resampled_encoded)),\n",
    "    'metric': 'multi_logloss',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'num_leaves': 64  # Set num_leaves <= 64 for max_depth=6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "18516134-1b73-46cc-99d9-5477e41c0eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': len(np.unique(y_train_resampled_encoded)),\n",
    "    'metric': 'multi_logloss',\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 64  # Control complexity using num_leaves alone\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "10aadf78-fe48-40a3-a89d-597444043ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot feature importance\n",
    "lgb.plot_importance(lgb_model, max_num_features=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d1abcc07-63b6-4f7d-af60-3389091e26f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Pop 18-24 Some College', 'Pop 18-24 Bachelors+', 'Pop 25-34 HS+',\n",
      "       'Pop 25-34 Bachelors+', 'Pop 35-44 HS+', 'Pop 35-44 Bachelors+',\n",
      "       'Pop 45-64 HS+', 'Pop 45-64 Bachelors+', 'Pop 65+ HS+',\n",
      "       'Pop 65+ Bachelors+', 'ZipCode'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "28905584-1acc-4485-b8fc-d9ffbb243c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: Pop 18-24 Some College, Importance: 2634\n",
      "Feature: Pop 18-24 Bachelors+, Importance: 2318\n",
      "Feature: Pop 25-34 HS+, Importance: 1895\n",
      "Feature: Pop 25-34 Bachelors+, Importance: 1814\n",
      "Feature: Pop 35-44 HS+, Importance: 1625\n",
      "Feature: Pop 35-44 Bachelors+, Importance: 1643\n",
      "Feature: Pop 45-64 HS+, Importance: 1777\n",
      "Feature: Pop 45-64 Bachelors+, Importance: 1589\n",
      "Feature: Pop 65+ HS+, Importance: 1796\n",
      "Feature: Pop 65+ Bachelors+, Importance: 1803\n",
      "Feature: ZipCode, Importance: 2067\n"
     ]
    }
   ],
   "source": [
    "# Get feature importances from the trained LightGBM model\n",
    "importances = lgb_model.feature_importance(importance_type='split')\n",
    "\n",
    "# Print the feature importances along with feature names to inspect the order\n",
    "for i, name in enumerate(feature_names):\n",
    "    print(f\"Feature: {name}, Importance: {importances[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0926a7a0-48a4-4eb2-9b54-d5eb21808a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature names corresponding to the top 10 most important columns\n",
    "top_10_feature_names = ['Pop 18-24 Some College', 'Pop 18-24 Bachelors+', 'Pop 25-34 HS+',\n",
    "                        'Pop 25-34 Bachelors+', 'Pop 35-44 HS+', 'Pop 35-44 Bachelors+',\n",
    "                        'Pop 45-64 HS+', 'Pop 45-64 Bachelors+', 'Pop 65+ HS+', 'Pop 65+ Bachelors+']\n",
    "\n",
    "# Plot feature importance with the correct number of labels\n",
    "ax = lgb.plot_importance(lgb_model, max_num_features=10)\n",
    "ax.set_yticklabels(top_10_feature_names)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "af62c0dd-0901-46bb-b165-98a584ce0eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns for training\n",
    "X_train_hist_cleaned = X_train_hist.drop(columns=['BUSINESS NAME', 'LOCATION START DATE', 'LOCATION', 'PRIMARY NAICS DESCRIPTION'])\n",
    "X_test_hist_cleaned = X_test_hist.drop(columns=['BUSINESS NAME', 'LOCATION START DATE', 'LOCATION', 'PRIMARY NAICS DESCRIPTION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a8afe1a8-d226-4c81-b374-4a50680b5698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing NAICS codes in both training and test sets\n",
    "y_train_hist_cleaned = y_train_hist.dropna()\n",
    "y_test_hist_cleaned = y_test_hist.dropna()\n",
    "\n",
    "# Now convert to integers\n",
    "y_train_hist_cleaned = y_train_hist_cleaned.astype(int)\n",
    "y_test_hist_cleaned = y_test_hist_cleaned.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "75b84a00-23ae-4b0c-ac3f-0535514161ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ZIP CODE to string for both training and test sets\n",
    "X_train_hist_cleaned['ZIP CODE'] = X_train_hist_cleaned['ZIP CODE'].astype(str).str[:5]\n",
    "X_test_hist_cleaned['ZIP CODE'] = X_test_hist_cleaned['ZIP CODE'].astype(str).str[:5]\n",
    "\n",
    "# Combine training and test sets temporarily\n",
    "combined_zipcodes = pd.concat([X_train_hist_cleaned['ZIP CODE'], X_test_hist_cleaned['ZIP CODE']])\n",
    "\n",
    "# Fit the LabelEncoder on the combined dataset\n",
    "le.fit(combined_zipcodes)\n",
    "\n",
    "# Now transform the individual sets\n",
    "X_train_hist_cleaned['ZIP CODE'] = le.transform(X_train_hist_cleaned['ZIP CODE'])\n",
    "X_test_hist_cleaned['ZIP CODE'] = le.transform(X_test_hist_cleaned['ZIP CODE'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "166a02bf-2498-460f-8424-e74a97dcfcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine training and test sets temporarily to fit the LabelEncoder\n",
    "combined_zipcodes = pd.concat([X_train_hist_cleaned['ZIP CODE'], X_test_hist_cleaned['ZIP CODE']])\n",
    "\n",
    "# Fit the LabelEncoder on the combined dataset\n",
    "le.fit(combined_zipcodes)\n",
    "\n",
    "# Now transform the individual sets\n",
    "X_train_hist_cleaned['ZIP CODE'] = le.transform(X_train_hist_cleaned['ZIP CODE'])\n",
    "X_test_hist_cleaned['ZIP CODE'] = le.transform(X_test_hist_cleaned['ZIP CODE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4c1d780f-3123-4d63-a5e1-85caf337b2ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [334220.0, 335999.0, 541519.0, 541612.0, 541613.0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m y_train_hist_encoded \u001b[38;5;241m=\u001b[39m le_naics\u001b[38;5;241m.\u001b[39mfit_transform(y_train_hist)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Apply the same transformation to the test labels (make sure all NAICS codes are seen)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m y_test_hist_encoded \u001b[38;5;241m=\u001b[39m le_naics\u001b[38;5;241m.\u001b[39mtransform(y_test_hist)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:137\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _encode(y, uniques\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_encode.py:232\u001b[0m, in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    230\u001b[0m     diff \u001b[38;5;241m=\u001b[39m _check_unknown(values, uniques)\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m diff:\n\u001b[0;32m--> 232\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(diff)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msearchsorted(uniques, values)\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: [334220.0, 335999.0, 541519.0, 541612.0, 541613.0]"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "le_naics = LabelEncoder()\n",
    "\n",
    "# Fit the LabelEncoder on the training labels (NAICS codes)\n",
    "y_train_hist_encoded = le_naics.fit_transform(y_train_hist)\n",
    "\n",
    "# Apply the same transformation to the test labels (make sure all NAICS codes are seen)\n",
    "y_test_hist_encoded = le_naics.transform(y_test_hist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "47c56b14-48ac-4b24-ac9b-0f30c93ed561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Label must be in [0, 6), but found 541510 in label\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Label must be in [0, 6), but found 541510 in label",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 15\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Train the LightGBM model on historical data\u001b[39;00m\n\u001b[1;32m      8\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_class\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_train_hist)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     14\u001b[0m }\n\u001b[0;32m---> 15\u001b[0m lgb_model_hist \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mtrain(params, train_hist_data, num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set (future period)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m y_pred_probs_hist \u001b[38;5;241m=\u001b[39m lgb_model_hist\u001b[38;5;241m.\u001b[39mpredict(X_test_hist_cleaned)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightgbm/engine.py:282\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 282\u001b[0m     booster \u001b[38;5;241m=\u001b[39m Booster(params\u001b[38;5;241m=\u001b[39mparams, train_set\u001b[38;5;241m=\u001b[39mtrain_set)\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[1;32m    284\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightgbm/basic.py:3641\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[0;34m(self, params, train_set, model_file, model_str)\u001b[0m\n\u001b[1;32m   3639\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(train_set\u001b[38;5;241m.\u001b[39mget_params())\n\u001b[1;32m   3640\u001b[0m params_str \u001b[38;5;241m=\u001b[39m _param_dict_to_str(params)\n\u001b[0;32m-> 3641\u001b[0m _safe_call(\n\u001b[1;32m   3642\u001b[0m     _LIB\u001b[38;5;241m.\u001b[39mLGBM_BoosterCreate(\n\u001b[1;32m   3643\u001b[0m         train_set\u001b[38;5;241m.\u001b[39m_handle,\n\u001b[1;32m   3644\u001b[0m         _c_str(params_str),\n\u001b[1;32m   3645\u001b[0m         ctypes\u001b[38;5;241m.\u001b[39mbyref(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle),\n\u001b[1;32m   3646\u001b[0m     )\n\u001b[1;32m   3647\u001b[0m )\n\u001b[1;32m   3648\u001b[0m \u001b[38;5;66;03m# save reference to data\u001b[39;00m\n\u001b[1;32m   3649\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_set \u001b[38;5;241m=\u001b[39m train_set\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightgbm/basic.py:296\u001b[0m, in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m    The return value from C API calls.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 296\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(_LIB\u001b[38;5;241m.\u001b[39mLGBM_GetLastError()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mLightGBMError\u001b[0m: Label must be in [0, 6), but found 541510 in label"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Create the dataset for LightGBM\n",
    "train_hist_data = lgb.Dataset(X_train_hist_cleaned, label=y_train_hist)\n",
    "test_hist_data = lgb.Dataset(X_test_hist_cleaned, label=y_test_hist)\n",
    "\n",
    "# Train the LightGBM model on historical data\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': len(np.unique(y_train_hist)),\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': -1\n",
    "}\n",
    "lgb_model_hist = lgb.train(params, train_hist_data, num_boost_round=200)\n",
    "\n",
    "# Make predictions on the test set (future period)\n",
    "y_pred_probs_hist = lgb_model_hist.predict(X_test_hist_cleaned)\n",
    "y_pred_adjusted_hist = np.argmax(y_pred_probs_hist, axis=1)  # Select the class with the highest probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8a04f3-9349-421c-b674-c04278bdd830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc06a99-0a6a-4d3b-93fc-607b18913064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "58f43519-c83d-4f40-96f8-68548e70ef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data based on year\n",
    "train_data = data[data['Year'] <= 2018]  # Historical data for training\n",
    "test_data = data[data['Year'] > 2018]    # Future data for validation\n",
    "\n",
    "# Separate features and target variable (NAICS codes)\n",
    "X_train_hist = train_data.drop(columns=['NAICS'])\n",
    "y_train_hist = train_data['NAICS']\n",
    "\n",
    "X_test_hist = test_data.drop(columns=['NAICS'])\n",
    "y_test_hist = test_data['NAICS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bce72d9b-7593-4375-b8a6-9f3049062331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique encoded labels in training set: [ 0  3  4  5  7 10]\n",
      "Unique encoded labels in test set: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Label must be in [0, 6), but found 7 in label\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Label must be in [0, 6), but found 7 in label",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 41\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Train the LightGBM model\u001b[39;00m\n\u001b[1;32m     33\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_class\u001b[39m\u001b[38;5;124m'\u001b[39m: num_classes,  \u001b[38;5;66;03m# Use the actual number of unique classes\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     39\u001b[0m }\n\u001b[0;32m---> 41\u001b[0m lgb_model_hist \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mtrain(params, train_hist_data, num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set\u001b[39;00m\n\u001b[1;32m     44\u001b[0m y_pred_probs_hist \u001b[38;5;241m=\u001b[39m lgb_model_hist\u001b[38;5;241m.\u001b[39mpredict(X_test_hist_cleaned)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightgbm/engine.py:282\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 282\u001b[0m     booster \u001b[38;5;241m=\u001b[39m Booster(params\u001b[38;5;241m=\u001b[39mparams, train_set\u001b[38;5;241m=\u001b[39mtrain_set)\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[1;32m    284\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightgbm/basic.py:3641\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[0;34m(self, params, train_set, model_file, model_str)\u001b[0m\n\u001b[1;32m   3639\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(train_set\u001b[38;5;241m.\u001b[39mget_params())\n\u001b[1;32m   3640\u001b[0m params_str \u001b[38;5;241m=\u001b[39m _param_dict_to_str(params)\n\u001b[0;32m-> 3641\u001b[0m _safe_call(\n\u001b[1;32m   3642\u001b[0m     _LIB\u001b[38;5;241m.\u001b[39mLGBM_BoosterCreate(\n\u001b[1;32m   3643\u001b[0m         train_set\u001b[38;5;241m.\u001b[39m_handle,\n\u001b[1;32m   3644\u001b[0m         _c_str(params_str),\n\u001b[1;32m   3645\u001b[0m         ctypes\u001b[38;5;241m.\u001b[39mbyref(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle),\n\u001b[1;32m   3646\u001b[0m     )\n\u001b[1;32m   3647\u001b[0m )\n\u001b[1;32m   3648\u001b[0m \u001b[38;5;66;03m# save reference to data\u001b[39;00m\n\u001b[1;32m   3649\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_set \u001b[38;5;241m=\u001b[39m train_set\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightgbm/basic.py:296\u001b[0m, in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m    The return value from C API calls.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 296\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(_LIB\u001b[38;5;241m.\u001b[39mLGBM_GetLastError()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mLightGBMError\u001b[0m: Label must be in [0, 6), but found 7 in label"
     ]
    }
   ],
   "source": [
    "# Option 1: Fill missing values with a default value (-1)\n",
    "y_train_hist = y_train_hist.fillna(-1).astype(int)\n",
    "y_test_hist = y_test_hist.fillna(-1).astype(int)\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Combine both training and test labels\n",
    "combined_labels = pd.concat([y_train_hist, y_test_hist])\n",
    "\n",
    "# Fit the LabelEncoder on the combined labels to create sequential labels\n",
    "le_naics = LabelEncoder()\n",
    "le_naics.fit(combined_labels)\n",
    "\n",
    "# Transform both training and test labels\n",
    "y_train_hist_encoded = le_naics.transform(y_train_hist)\n",
    "y_test_hist_encoded = le_naics.transform(y_test_hist)\n",
    "\n",
    "# Ensure that the labels are continuous and sequential\n",
    "print(\"Unique encoded labels in training set:\", np.unique(y_train_hist_encoded))\n",
    "print(\"Unique encoded labels in test set:\", np.unique(y_test_hist_encoded))\n",
    "\n",
    "# Create the LightGBM datasets with the encoded labels\n",
    "train_hist_data = lgb.Dataset(X_train_hist_cleaned, label=y_train_hist_encoded)\n",
    "test_hist_data = lgb.Dataset(X_test_hist_cleaned, label=y_test_hist_encoded)\n",
    "\n",
    "# Update num_class to reflect the correct number of classes after re-encoding\n",
    "num_classes = len(np.unique(y_train_hist_encoded))\n",
    "\n",
    "# Train the LightGBM model\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': num_classes,  # Use the actual number of unique classes\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': -1\n",
    "}\n",
    "\n",
    "lgb_model_hist = lgb.train(params, train_hist_data, num_boost_round=200)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_probs_hist = lgb_model_hist.predict(X_test_hist_cleaned)\n",
    "\n",
    "# Select the class with the highest probability\n",
    "y_pred_adjusted_hist = np.argmax(y_pred_probs_hist, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "28b1964a-0cb4-4b34-933a-dd0bc16bee3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing labels in training set: {1, 2, 6, 8, 9}\n",
      "Unique labels in filtered test set: [ 0  3  4  5  7 10]\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Label must be in [0, 6), but found 7 in label\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Label must be in [0, 6), but found 7 in label",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 26\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Train the LightGBM model\u001b[39;00m\n\u001b[1;32m     18\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_class\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_train_hist_encoded)),  \u001b[38;5;66;03m# Use the actual number of unique classes in the training set\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     24\u001b[0m }\n\u001b[0;32m---> 26\u001b[0m lgb_model_hist \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mtrain(params, train_hist_data, num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Make predictions on the filtered test set\u001b[39;00m\n\u001b[1;32m     29\u001b[0m y_pred_probs_hist \u001b[38;5;241m=\u001b[39m lgb_model_hist\u001b[38;5;241m.\u001b[39mpredict(X_test_hist_filtered)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightgbm/engine.py:282\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 282\u001b[0m     booster \u001b[38;5;241m=\u001b[39m Booster(params\u001b[38;5;241m=\u001b[39mparams, train_set\u001b[38;5;241m=\u001b[39mtrain_set)\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[1;32m    284\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightgbm/basic.py:3641\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[0;34m(self, params, train_set, model_file, model_str)\u001b[0m\n\u001b[1;32m   3639\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(train_set\u001b[38;5;241m.\u001b[39mget_params())\n\u001b[1;32m   3640\u001b[0m params_str \u001b[38;5;241m=\u001b[39m _param_dict_to_str(params)\n\u001b[0;32m-> 3641\u001b[0m _safe_call(\n\u001b[1;32m   3642\u001b[0m     _LIB\u001b[38;5;241m.\u001b[39mLGBM_BoosterCreate(\n\u001b[1;32m   3643\u001b[0m         train_set\u001b[38;5;241m.\u001b[39m_handle,\n\u001b[1;32m   3644\u001b[0m         _c_str(params_str),\n\u001b[1;32m   3645\u001b[0m         ctypes\u001b[38;5;241m.\u001b[39mbyref(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle),\n\u001b[1;32m   3646\u001b[0m     )\n\u001b[1;32m   3647\u001b[0m )\n\u001b[1;32m   3648\u001b[0m \u001b[38;5;66;03m# save reference to data\u001b[39;00m\n\u001b[1;32m   3649\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_set \u001b[38;5;241m=\u001b[39m train_set\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightgbm/basic.py:296\u001b[0m, in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m    The return value from C API calls.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 296\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(_LIB\u001b[38;5;241m.\u001b[39mLGBM_GetLastError()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mLightGBMError\u001b[0m: Label must be in [0, 6), but found 7 in label"
     ]
    }
   ],
   "source": [
    "# Find the labels that are missing in the training set but present in the test set\n",
    "missing_labels_in_train = set(np.unique(y_test_hist_encoded)) - set(np.unique(y_train_hist_encoded))\n",
    "print(\"Missing labels in training set:\", missing_labels_in_train)\n",
    "\n",
    "# Filter out the test data that has labels missing in the training set\n",
    "mask = ~np.isin(y_test_hist_encoded, list(missing_labels_in_train))\n",
    "X_test_hist_filtered = X_test_hist_cleaned[mask]\n",
    "y_test_hist_filtered = y_test_hist_encoded[mask]\n",
    "\n",
    "# Check the unique labels after filtering\n",
    "print(\"Unique labels in filtered test set:\", np.unique(y_test_hist_filtered))\n",
    "\n",
    "# Now train the model\n",
    "train_hist_data = lgb.Dataset(X_train_hist_cleaned, label=y_train_hist_encoded)\n",
    "test_hist_data = lgb.Dataset(X_test_hist_filtered, label=y_test_hist_filtered)\n",
    "\n",
    "# Train the LightGBM model\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': len(np.unique(y_train_hist_encoded)),  # Use the actual number of unique classes in the training set\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': -1\n",
    "}\n",
    "\n",
    "lgb_model_hist = lgb.train(params, train_hist_data, num_boost_round=200)\n",
    "\n",
    "# Make predictions on the filtered test set\n",
    "y_pred_probs_hist = lgb_model_hist.predict(X_test_hist_filtered)\n",
    "\n",
    "# Select the class with the highest probability\n",
    "y_pred_adjusted_hist = np.argmax(y_pred_probs_hist, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "84503d22-19f2-4479-bed9-f3f46b89ac38",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [334220, 335999, 541519, 541612, 541613]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m y_train_hist_encoded \u001b[38;5;241m=\u001b[39m le_naics\u001b[38;5;241m.\u001b[39mfit_transform(y_train_hist)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Apply the same encoding to the test set\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m y_test_hist_encoded \u001b[38;5;241m=\u001b[39m le_naics\u001b[38;5;241m.\u001b[39mtransform(y_test_hist)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Filter the test set to only include the labels that exist in the training set\u001b[39;00m\n\u001b[1;32m     15\u001b[0m unique_train_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_train_hist_encoded)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:137\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _encode(y, uniques\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_encode.py:232\u001b[0m, in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    230\u001b[0m     diff \u001b[38;5;241m=\u001b[39m _check_unknown(values, uniques)\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m diff:\n\u001b[0;32m--> 232\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(diff)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msearchsorted(uniques, values)\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: [334220, 335999, 541519, 541612, 541613]"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Re-encode the target labels to avoid unseen labels issue\n",
    "le_naics = LabelEncoder()\n",
    "\n",
    "# Fit the label encoder on the training set\n",
    "y_train_hist_encoded = le_naics.fit_transform(y_train_hist)\n",
    "\n",
    "# Apply the same encoding to the test set\n",
    "y_test_hist_encoded = le_naics.transform(y_test_hist)\n",
    "\n",
    "# Filter the test set to only include the labels that exist in the training set\n",
    "unique_train_labels = np.unique(y_train_hist_encoded)\n",
    "mask = np.isin(y_test_hist_encoded, unique_train_labels)\n",
    "X_test_hist_filtered = X_test_hist_cleaned[mask]\n",
    "y_test_hist_filtered = y_test_hist_encoded[mask]\n",
    "\n",
    "# Check the unique labels in the filtered test set\n",
    "print(f\"Unique labels in filtered test set: {np.unique(y_test_hist_filtered)}\")\n",
    "\n",
    "# Create the LightGBM datasets with the filtered labels\n",
    "train_hist_data = lgb.Dataset(X_train_hist_cleaned, label=y_train_hist_encoded)\n",
    "test_hist_data = lgb.Dataset(X_test_hist_filtered, label=y_test_hist_filtered)\n",
    "\n",
    "# Train the LightGBM model\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': len(np.unique(y_train_hist_encoded)),  # Use the actual number of unique classes in the training set\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': -1\n",
    "}\n",
    "\n",
    "# Train the LightGBM model\n",
    "lgb_model_hist = lgb.train(params, train_hist_data, num_boost_round=200)\n",
    "\n",
    "# Make predictions on the filtered test set\n",
    "y_pred_probs_hist = lgb_model_hist.predict(X_test_hist_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f1eb5e0f-bca3-4ff8-bfe9-250d2ebecc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered test set labels: [0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Identify the unique labels in the training set after encoding\n",
    "unique_train_labels = np.unique(y_train_hist)\n",
    "\n",
    "# Filter the test set to only include rows where the label exists in the training set\n",
    "mask = y_test_hist.isin(unique_train_labels)\n",
    "X_test_hist_filtered = X_test_hist_cleaned[mask]\n",
    "y_test_hist_filtered = y_test_hist[mask]\n",
    "\n",
    "# Encode the filtered test labels using the same LabelEncoder\n",
    "y_test_hist_encoded_filtered = le_naics.transform(y_test_hist_filtered)\n",
    "\n",
    "# Check the unique labels in the filtered test set\n",
    "print(\"Filtered test set labels:\", np.unique(y_test_hist_encoded_filtered))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d3bc5b11-8132-49f3-8e01-c3e0c7229853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1760\n",
      "[LightGBM] [Info] Number of data points in the train set: 2449, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -5.095385\n",
      "[LightGBM] [Info] Start training from score -2.813002\n",
      "[LightGBM] [Info] Start training from score -2.861793\n",
      "[LightGBM] [Info] Start training from score -1.644340\n",
      "[LightGBM] [Info] Start training from score -0.428806\n",
      "[LightGBM] [Info] Start training from score -3.433987\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "# Create the LightGBM datasets with the filtered test set\n",
    "train_hist_data = lgb.Dataset(X_train_hist_cleaned, label=y_train_hist_encoded)\n",
    "test_hist_data = lgb.Dataset(X_test_hist_filtered, label=y_test_hist_encoded_filtered)\n",
    "\n",
    "# Define the parameters for the LightGBM model\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': len(np.unique(y_train_hist_encoded)),  # Number of classes in the training set\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': -1\n",
    "}\n",
    "\n",
    "# Train the LightGBM model\n",
    "lgb_model_hist = lgb.train(params, train_hist_data, num_boost_round=200)\n",
    "\n",
    "# Make predictions on the filtered test set\n",
    "y_pred_probs_hist = lgb_model_hist.predict(X_test_hist_filtered)\n",
    "\n",
    "# You can now proceed with adjusting the decision threshold and evaluating the predictions as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e6c0b51f-7416-49fb-8a83-86e99d16bb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class probabilities for the test set\n",
    "y_pred_probs_hist = lgb_model_hist.predict(X_test_hist_filtered)\n",
    "\n",
    "# Get the predicted class by selecting the class with the highest probability\n",
    "y_pred_hist = np.argmax(y_pred_probs_hist, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "407b0ef9-028b-4a9e-a45c-c19bd6fd4ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       9.0\n",
      "           0       0.00      0.00      0.00       0.0\n",
      "           3       0.00      0.00      0.00       0.0\n",
      "           4       0.00      0.00      0.00       0.0\n",
      "      518210       0.00      0.00      0.00      83.0\n",
      "      519100       0.00      0.00      0.00      62.0\n",
      "      541510       0.00      0.00      0.00     176.0\n",
      "      541600       0.00      0.00      0.00     669.0\n",
      "      541700       0.00      0.00      0.00      41.0\n",
      "\n",
      "    accuracy                           0.00    1040.0\n",
      "   macro avg       0.00      0.00      0.00    1040.0\n",
      "weighted avg       0.00      0.00      0.00    1040.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/admin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/admin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/admin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/admin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/admin/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Print accuracy\n",
    "accuracy = accuracy_score(y_test_hist_filtered, y_pred_hist)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Print classification report for precision, recall, and F1-score\n",
    "print(classification_report(y_test_hist_filtered, y_pred_hist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9ef2186b-b065-4b3d-a9b0-f84856437cee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nSMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m      2\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE()\n\u001b[0;32m----> 3\u001b[0m X_train_resampled, y_train_resampled \u001b[38;5;241m=\u001b[39m smote\u001b[38;5;241m.\u001b[39mfit_resample(X_train_hist_cleaned, y_train_hist_encoded)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_resample(X, y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/base.py:106\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    104\u001b[0m check_classification_targets(y)\n\u001b[1;32m    105\u001b[0m arrays_transformer \u001b[38;5;241m=\u001b[39m ArraysTransformer(X, y)\n\u001b[0;32m--> 106\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[1;32m    110\u001b[0m )\n\u001b[1;32m    112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resample(X, y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/base.py:161\u001b[0m, in \u001b[0;36mBaseSampler._check_X_y\u001b[0;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[1;32m    159\u001b[0m     accept_sparse \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    160\u001b[0m y, binarize_y \u001b[38;5;241m=\u001b[39m check_target_type(y, indicate_one_vs_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 161\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, y, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y, binarize_y\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1299\u001b[0m     )\n\u001b[0;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1302\u001b[0m     X,\n\u001b[1;32m   1303\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   1304\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[1;32m   1305\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1306\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[1;32m   1307\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m   1308\u001b[0m     force_writeable\u001b[38;5;241m=\u001b[39mforce_writeable,\n\u001b[1;32m   1309\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[1;32m   1310\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[1;32m   1311\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[1;32m   1312\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[1;32m   1313\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[1;32m   1314\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m   1315\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1316\u001b[0m )\n\u001b[1;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1061\u001b[0m     )\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1064\u001b[0m     _assert_all_finite(\n\u001b[1;32m   1065\u001b[0m         array,\n\u001b[1;32m   1066\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m   1067\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m   1068\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1069\u001b[0m     )\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m _assert_all_finite_element_wise(\n\u001b[1;32m    124\u001b[0m     X,\n\u001b[1;32m    125\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[1;32m    126\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[1;32m    127\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[1;32m    128\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    129\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    130\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m     )\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nSMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_hist_cleaned, y_train_hist_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c39fb99f-e03f-424f-a2da-3508365a8f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HistGradientBoostingClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;HistGradientBoostingClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html\">?<span>Documentation for HistGradientBoostingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>HistGradientBoostingClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "HistGradientBoostingClassifier()"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "# Initialize the model\n",
    "hgb_model = HistGradientBoostingClassifier()\n",
    "\n",
    "# Fit the model directly without needing to impute missing values\n",
    "hgb_model.fit(X_train_hist_cleaned, y_train_hist_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "485e2548-f7d6-471f-8acc-37055ee2b628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Label must be in [0, 5), but found 541510 in label\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Label must be in [0, 5), but found 541510 in label",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 13\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Train the LightGBM model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_class\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_train_resampled)),  \u001b[38;5;66;03m# Number of classes\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     11\u001b[0m }\n\u001b[0;32m---> 13\u001b[0m lgb_model_hist \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mtrain(params, train_hist_data, num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set\u001b[39;00m\n\u001b[1;32m     16\u001b[0m y_pred_probs_hist \u001b[38;5;241m=\u001b[39m lgb_model_hist\u001b[38;5;241m.\u001b[39mpredict(X_test_hist_cleaned)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightgbm/engine.py:282\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 282\u001b[0m     booster \u001b[38;5;241m=\u001b[39m Booster(params\u001b[38;5;241m=\u001b[39mparams, train_set\u001b[38;5;241m=\u001b[39mtrain_set)\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[1;32m    284\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightgbm/basic.py:3641\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[0;34m(self, params, train_set, model_file, model_str)\u001b[0m\n\u001b[1;32m   3639\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(train_set\u001b[38;5;241m.\u001b[39mget_params())\n\u001b[1;32m   3640\u001b[0m params_str \u001b[38;5;241m=\u001b[39m _param_dict_to_str(params)\n\u001b[0;32m-> 3641\u001b[0m _safe_call(\n\u001b[1;32m   3642\u001b[0m     _LIB\u001b[38;5;241m.\u001b[39mLGBM_BoosterCreate(\n\u001b[1;32m   3643\u001b[0m         train_set\u001b[38;5;241m.\u001b[39m_handle,\n\u001b[1;32m   3644\u001b[0m         _c_str(params_str),\n\u001b[1;32m   3645\u001b[0m         ctypes\u001b[38;5;241m.\u001b[39mbyref(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle),\n\u001b[1;32m   3646\u001b[0m     )\n\u001b[1;32m   3647\u001b[0m )\n\u001b[1;32m   3648\u001b[0m \u001b[38;5;66;03m# save reference to data\u001b[39;00m\n\u001b[1;32m   3649\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_set \u001b[38;5;241m=\u001b[39m train_set\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/lightgbm/basic.py:296\u001b[0m, in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m    The return value from C API calls.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 296\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(_LIB\u001b[38;5;241m.\u001b[39mLGBM_GetLastError()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mLightGBMError\u001b[0m: Label must be in [0, 5), but found 541510 in label"
     ]
    }
   ],
   "source": [
    "# Train the LightGBM model after handling missing values or applying SMOTE\n",
    "train_hist_data = lgb.Dataset(X_train_resampled, label=y_train_resampled)\n",
    "\n",
    "# Train the LightGBM model\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': len(np.unique(y_train_resampled)),  # Number of classes\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': -1\n",
    "}\n",
    "\n",
    "lgb_model_hist = lgb.train(params, train_hist_data, num_boost_round=200)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_probs_hist = lgb_model_hist.predict(X_test_hist_cleaned)\n",
    "y_pred_hist = np.argmax(y_pred_probs_hist, axis=1)  # Convert probabilities to class predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31594f9d-2f11-4390-adb8-2a92f2751a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b310e6d-997c-4925-bf42-847b8cca33ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ca2540-7650-42e3-95b8-635b48717d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c858f3b-9b1f-42c9-ae82-63666589ca2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (10), usually from a call to set_ticks, does not match the number of labels (11).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Plot feature importance with proper labels\u001b[39;00m\n\u001b[1;32m     10\u001b[0m ax \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mplot_importance(lgb_model, max_num_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_yticklabels(feature_names)\n\u001b[1;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/matplotlib/axes/_base.py:74\u001b[0m, in \u001b[0;36m_axis_method_wrapper.__set_name__.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_method(\u001b[38;5;28mself\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/matplotlib/_api/deprecation.py:297\u001b[0m, in \u001b[0;36mrename_parameter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m     warn_deprecated(\n\u001b[1;32m    293\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas been renamed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m since Matplotlib \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msince\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; support \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor the old name will be dropped %(removal)s.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    296\u001b[0m     kwargs[new] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(old)\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/matplotlib/axis.py:1969\u001b[0m, in \u001b[0;36mAxis.set_ticklabels\u001b[0;34m(self, labels, minor, fontdict, **kwargs)\u001b[0m\n\u001b[1;32m   1965\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(locator, mticker\u001b[38;5;241m.\u001b[39mFixedLocator):\n\u001b[1;32m   1966\u001b[0m     \u001b[38;5;66;03m# Passing [] as a list of labels is often used as a way to\u001b[39;00m\n\u001b[1;32m   1967\u001b[0m     \u001b[38;5;66;03m# remove all tick labels, so only error for > 0 labels\u001b[39;00m\n\u001b[1;32m   1968\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1969\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1970\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of FixedLocator locations\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1971\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), usually from a call to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1972\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m set_ticks, does not match\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1973\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m the number of labels (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(labels)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1974\u001b[0m     tickd \u001b[38;5;241m=\u001b[39m {loc: lab \u001b[38;5;28;01mfor\u001b[39;00m loc, lab \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(locator\u001b[38;5;241m.\u001b[39mlocs, labels)}\n\u001b[1;32m   1975\u001b[0m     func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_with_dict, tickd)\n",
      "\u001b[0;31mValueError\u001b[0m: The number of FixedLocator locations (10), usually from a call to set_ticks, does not match the number of labels (11)."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Feature names corresponding to the columns in the plot\n",
    "feature_names = ['Pop 18-24 Some College', 'Pop 18-24 Bachelors+', 'Pop 25-34 HS+',\n",
    "                 'Pop 25-34 Bachelors+', 'Pop 35-44 HS+', 'Pop 35-44 Bachelors+',\n",
    "                 'Pop 45-64 HS+', 'Pop 45-64 Bachelors+', 'Pop 65+ HS+',\n",
    "                 'Pop 65+ Bachelors+', 'ZipCode']\n",
    "\n",
    "# Plot feature importance with proper labels\n",
    "ax = lgb.plot_importance(lgb_model, max_num_features=10)\n",
    "ax.set_yticklabels(feature_names)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3ad3b63a-4fe4-4a56-a263-062ca805df8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_adjusted_hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_score, recall_score, f1_score\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Evaluate the model's performance on the future period\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m precision_hist \u001b[38;5;241m=\u001b[39m precision_score(y_test_hist, y_pred_adjusted_hist, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m recall_hist \u001b[38;5;241m=\u001b[39m recall_score(y_test_hist, y_pred_adjusted_hist, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m f1_hist \u001b[38;5;241m=\u001b[39m f1_score(y_test_hist, y_pred_adjusted_hist, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred_adjusted_hist' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Evaluate the model's performance on the future period\n",
    "precision_hist = precision_score(y_test_hist, y_pred_adjusted_hist, average='macro', zero_division=1)\n",
    "recall_hist = recall_score(y_test_hist, y_pred_adjusted_hist, average='macro', zero_division=1)\n",
    "f1_hist = f1_score(y_test_hist, y_pred_adjusted_hist, average='macro', zero_division=1)\n",
    "\n",
    "print(f'Historical Validation - Precision: {precision_hist:.2f}')\n",
    "print(f'Historical Validation - Recall: {recall_hist:.2f}')\n",
    "print(f'Historical Validation - F1-Score: {f1_hist:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd407039-2963-425b-83f9-c69a32e41c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fadf148-5c1b-476d-a252-51cd18ad084e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f85c0c0-4e3c-4ed9-9891-f0de2f8df3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9da5059-ba6b-4b2b-9c3b-3250a4460a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e29784-6773-453d-9448-eee673359d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a8f08f-2ff7-4a5c-9acc-6efd9cf25baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da645850-710f-45f9-8e1a-9c07aa1ea1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbbbf26-4a03-4d00-aa52-15bfafccfe2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b0965c-297e-4223-8190-b771a71df679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b1675d-7a7b-42b3-8e8c-a73787ebdffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6fc1be-7a24-42f0-82d8-57743e3af09a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a1d077-20ae-43ea-841b-d5d5b9fd1524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d2deaa7a-1512-4b9d-b866-9d9dbb516686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=6) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=64) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2789\n",
      "[LightGBM] [Info] Number of data points in the train set: 4365, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Info] Start training from score -1.609438\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM Precision: 0.63\n",
      "LightGBM Recall: 0.21\n",
      "LightGBM F1-Score: 0.04\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Create the dataset for LightGBM\n",
    "train_data = lgb.Dataset(X_train_resampled_scaled, label=y_train_resampled_encoded)\n",
    "test_data = lgb.Dataset(X_test_filtered, label=y_test_encoded, reference=train_data)\n",
    "\n",
    "# Set the parameters for LightGBM\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': len(np.unique(y_train_resampled_encoded)),\n",
    "    'metric': 'multi_logloss',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 6\n",
    "}\n",
    "\n",
    "# Train the LightGBM model\n",
    "lgb_model = lgb.train(params, train_data, num_boost_round=200)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_probs_lgb = lgb_model.predict(X_test_filtered)\n",
    "\n",
    "# Adjust the threshold (e.g., 0.3)\n",
    "y_pred_adjusted_lgb = (y_pred_probs_lgb[:, 1] >= 0.3).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "precision = precision_score(y_test_encoded, y_pred_adjusted_lgb, average='macro', zero_division=1)\n",
    "recall = recall_score(y_test_encoded, y_pred_adjusted_lgb, average='macro', zero_division=1)\n",
    "f1 = f1_score(y_test_encoded, y_pred_adjusted_lgb, average='macro', zero_division=1)\n",
    "\n",
    "print(f'LightGBM Precision: {precision:.2f}')\n",
    "print(f'LightGBM Recall: {recall:.2f}')\n",
    "print(f'LightGBM F1-Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746dfc7a-9b3e-4b3e-95a8-bbbe47ae2278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ec4f29-4e46-4428-a8a7-30a92de0aa4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c282778f-781b-435a-853a-bfb59b81ec2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b8ed3e-7b29-4d16-84b5-0ff4b9c13184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3848a8-10f1-4774-a18b-da976c0f1d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5812dc65-0218-4d21-9683-8738d1439823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842de8bf-78f5-471f-84b9-6c7e71bf2ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42afa285-489d-4f48-86b8-e304f2a6a19e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4fe62-39ea-4cb1-8ccb-f17943c6a3db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0623eac7-d8cf-4fa1-83c5-78259dafc171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67685b80-54ee-4d6f-8655-e1c670eefb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d65462e-b8cf-4de1-a060-99f0d1bdb3fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b9ff21-88c5-4f86-af24-2ac77849792a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6a2093-04d3-435a-8660-44c04bb557cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55ee0b9-f1d2-4bf7-8cb2-7d572e465e91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c4081b-1a56-4e98-9e60-0acb33e910f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb18790b-7720-4f48-b6bb-9341450851d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a14cba-4cf2-4a0c-a427-b70588e4e21f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dbeb72-15e1-4813-b81c-db97469040e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f8bc65-a4b0-4777-a44e-34d81004aa46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de346679-6ee2-4577-b8d3-c5b51d45fb27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
